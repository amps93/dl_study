{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6485d492-b646-4db7-9361-f1fe246dfff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import unicodedata\n",
    "import urllib3\n",
    "import zipfile\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0704f62c-76be-47b5-9809-2fffd89f527f",
   "metadata": {},
   "source": [
    "# 데이터 로드 및 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c6ed432-7def-4591-a032-0cb358bbeb2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 33000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f6c61b8c-e06b-4c73-bc03-36df30d2342f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "전처리 함수 구현\n",
    "\"\"\"\n",
    "\n",
    "def unicode_to_ascii(s):\n",
    "    # 프랑스어 악센트(accent) 삭제\n",
    "    # 예시 : 'déjà diné' -> deja dine\n",
    "    return ''.join(c for c in unicodedata.normalize('NFD', s) if unicodedata.category(c) != 'Mn')\n",
    "\n",
    "def preprocess_sentence(sent):\n",
    "    # 악센트 삭제 함수 호출\n",
    "    sent = unicode_to_ascii(sent.lower())\n",
    "\n",
    "    # 단어와 구두점 사이에 공백을 만듭니다.\n",
    "    # Ex) \"he is a boy.\" => \"he is a boy .\"\n",
    "    sent = re.sub(r\"([?.!,¿])\", r\" \\1\", sent)\n",
    "\n",
    "    # (a-z, A-Z, \".\", \"?\", \"!\", \",\") 이들을 제외하고는 전부 공백으로 변환합니다.\n",
    "    sent = re.sub(r\"[^a-zA-Z!.?]+\", r\" \", sent)\n",
    "\n",
    "    # 다수 개의 공백을 하나의 공백으로 치환\n",
    "    sent = re.sub(r\"\\s+\", \" \", sent)\n",
    "    return sent\n",
    "\n",
    "def load_preprocessed_data():\n",
    "    encoder_input, decoder_input, decoder_target = [], [], []\n",
    "\n",
    "    with open(\"fra.txt\", \"r\", encoding='utf8') as lines:\n",
    "        for i, line in enumerate(lines):\n",
    "            # source 데이터와 target 데이터 분리\n",
    "            src_line, tar_line, _ = line.strip().split('\\t')\n",
    "\n",
    "            # source 데이터 전처리\n",
    "            src_line = [w for w in preprocess_sentence(src_line).split()]\n",
    "\n",
    "            # target 데이터 전처리\n",
    "            tar_line = preprocess_sentence(tar_line)\n",
    "            tar_line_in = [w for w in (\"<sos> \" + tar_line).split()]\n",
    "            tar_line_out = [w for w in (tar_line + \" <eos>\").split()]\n",
    "\n",
    "            encoder_input.append(src_line)\n",
    "            decoder_input.append(tar_line_in)\n",
    "            decoder_target.append(tar_line_out)\n",
    "\n",
    "            if i == num_samples - 1:\n",
    "                break\n",
    "\n",
    "    return encoder_input, decoder_input, decoder_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a330e690-dd5b-4aea-9410-277e73510583",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전처리 전 영어 문장 : Have you had dinner?\n",
      "전처리 후 영어 문장 : have you had dinner ?\n",
      "전처리 전 프랑스어 문장 : Avez-vous déjà diné?\n",
      "전처리 후 프랑스어 문장 : avez vous deja dine ?\n"
     ]
    }
   ],
   "source": [
    "# 전처리 테스트\n",
    "en_sent = u\"Have you had dinner?\"\n",
    "fr_sent = u\"Avez-vous déjà diné?\"\n",
    "\n",
    "print('전처리 전 영어 문장 :', en_sent)\n",
    "print('전처리 후 영어 문장 :',preprocess_sentence(en_sent))\n",
    "print('전처리 전 프랑스어 문장 :', fr_sent)\n",
    "print('전처리 후 프랑스어 문장 :', preprocess_sentence(fr_sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "101b5508-e69e-4f6d-a458-67099a7a1625",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인코더의 입력 : [['go', '.'], ['go', '.'], ['go', '.'], ['go', '.'], ['hi', '.']]\n",
      "디코더의 입력 : [['<sos>', 'va', '!'], ['<sos>', 'marche', '.'], ['<sos>', 'en', 'route', '!'], ['<sos>', 'bouge', '!'], ['<sos>', 'salut', '!']]\n",
      "디코더의 레이블 : [['va', '!', '<eos>'], ['marche', '.', '<eos>'], ['en', 'route', '!', '<eos>'], ['bouge', '!', '<eos>'], ['salut', '!', '<eos>']]\n"
     ]
    }
   ],
   "source": [
    "sents_en_in, sents_fra_in, sents_fra_out = load_preprocessed_data()\n",
    "print('인코더의 입력 :',sents_en_in[:5])\n",
    "print('디코더의 입력 :',sents_fra_in[:5])\n",
    "print('디코더의 레이블 :',sents_fra_out[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3c9ce43c-d9e7-481e-919b-aa4cc630025a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "영어 단어 집합의 크기 : 4486, 프랑스어 단어 집합의 크기 : 7879\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "단어로부터 정수를 얻는 딕셔너리. 즉, 단어 집합(Vocabulary) 생성\n",
    "\"\"\"\n",
    "def build_vocab(sents):\n",
    "    word_list = []\n",
    "\n",
    "    for sent in sents:\n",
    "        for word in sent:\n",
    "            word_list.append(word)\n",
    "\n",
    "    # 각 단어별 등장 빈도를 계산하여 등장 빈도가 높은 순서로 정렬\n",
    "    word_counts = Counter(word_list)\n",
    "    vocab = sorted(word_counts, key=word_counts.get, reverse=True)\n",
    "\n",
    "    word_to_index = {}\n",
    "    word_to_index['<PAD>'] = 0\n",
    "    word_to_index['<UNK>'] = 1\n",
    "\n",
    "    # 등장 빈도가 높은 단어일수록 낮은 정수를 부여\n",
    "    for index, word in enumerate(vocab) :\n",
    "        word_to_index[word] = index + 2\n",
    "\n",
    "    return word_to_index\n",
    "\n",
    "src_vocab = build_vocab(sents_en_in)\n",
    "tar_vocab = build_vocab(sents_fra_in + sents_fra_out)\n",
    "\n",
    "src_vocab_size = len(src_vocab)\n",
    "tar_vocab_size = len(tar_vocab)\n",
    "print(\"영어 단어 집합의 크기 : {:d}, 프랑스어 단어 집합의 크기 : {:d}\".format(src_vocab_size, tar_vocab_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "27a62c57-980a-47ab-a9c7-e415e0f963b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 33000/33000 [00:00<00:00, 292243.41it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 33000/33000 [00:00<00:00, 1155610.00it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 33000/33000 [00:00<00:00, 1179249.33it/s]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "정수로부터 단어를 얻는 딕셔너리를 각각 만들어줌. 이들은 훈련을 마치고 예측값과 실제값을 비교하는 단계에서 사용\n",
    "\"\"\"\n",
    "index_to_src = {v: k for k, v in src_vocab.items()}\n",
    "index_to_tar = {v: k for k, v in tar_vocab.items()}\n",
    "\n",
    "def texts_to_sequences(sents, word_to_index):\n",
    "    encoded_X_data = []\n",
    "    for sent in tqdm(sents):\n",
    "        index_sequences = []\n",
    "        for word in sent:\n",
    "            try:\n",
    "                index_sequences.append(word_to_index[word])\n",
    "            except KeyError:\n",
    "                index_sequences.append(word_to_index['<UNK>'])\n",
    "        encoded_X_data.append(index_sequences)\n",
    "    return encoded_X_data\n",
    "\n",
    "encoder_input = texts_to_sequences(sents_en_in, src_vocab)\n",
    "decoder_input = texts_to_sequences(sents_fra_in, tar_vocab)\n",
    "decoder_target = texts_to_sequences(sents_fra_out, tar_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d9c09bf8-fda0-49be-bfc9-bfaf2a50f863",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index: 0, 정수 인코딩 전: ['go', '.'], 정수 인코딩 후: [27, 2]\n",
      "Index: 1, 정수 인코딩 전: ['go', '.'], 정수 인코딩 후: [27, 2]\n",
      "Index: 2, 정수 인코딩 전: ['go', '.'], 정수 인코딩 후: [27, 2]\n",
      "Index: 3, 정수 인코딩 전: ['go', '.'], 정수 인코딩 후: [27, 2]\n",
      "Index: 4, 정수 인코딩 전: ['hi', '.'], 정수 인코딩 후: [736, 2]\n"
     ]
    }
   ],
   "source": [
    "# 상위 5개의 샘플에 대해서 정수 인코딩 전, 후 문장 출력\n",
    "# 인코더 입력이므로 <sos>나 <eos>가 없음\n",
    "for i, (item1, item2) in zip(range(5), zip(sents_en_in, encoder_input)):\n",
    "    print(f\"Index: {i}, 정수 인코딩 전: {item1}, 정수 인코딩 후: {item2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ffbc1945-fb24-4767-97ce-316414e1c644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인코더의 입력의 크기(shape) : (33000, 7)\n",
      "디코더의 입력의 크기(shape) : (33000, 16)\n",
      "디코더의 레이블의 크기(shape) : (33000, 16)\n"
     ]
    }
   ],
   "source": [
    "def pad_sequences(sentences, max_len=None):\n",
    "    # 최대 길이 값이 주어지지 않을 경우 데이터 내 최대 길이로 패딩\n",
    "    if max_len is None:\n",
    "        max_len = max([len(sentence) for sentence in sentences])\n",
    "\n",
    "    features = np.zeros((len(sentences), max_len), dtype=int)\n",
    "    for index, sentence in enumerate(sentences):\n",
    "        if len(sentence) != 0:\n",
    "            features[index, :len(sentence)] = np.array(sentence)[:max_len]\n",
    "    return features\n",
    "\n",
    "encoder_input = pad_sequences(encoder_input)\n",
    "decoder_input = pad_sequences(decoder_input)\n",
    "decoder_target = pad_sequences(decoder_target)\n",
    "\n",
    "# 데이터 shape 확인\n",
    "print('인코더의 입력의 크기(shape) :',encoder_input.shape)\n",
    "print('디코더의 입력의 크기(shape) :',decoder_input.shape)\n",
    "print('디코더의 레이블의 크기(shape) :',decoder_target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cfb7640e-8b2f-4851-a641-c3adfd2c3e7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33000, 7)\n",
      "랜덤 시퀀스 : [16032 32333  6125 ... 11920 18199 20987]\n"
     ]
    }
   ],
   "source": [
    "# 테스트 데이터를 분리하기 전 데이터를 섞어줍니다. 이를 위해서 순서가 섞인 정수 시퀀스 리스트를 만듭니다.\n",
    "print(encoder_input.shape)\n",
    "indices = np.arange(encoder_input.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "print('랜덤 시퀀스 :', indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ce09b59b-0dd1-487d-81f2-b0e4f5d4deff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['what', 'is', 'your', 'name', '?', '<PAD>', '<PAD>']\n",
      "['<sos>', 'comment', 'est', 'ce', 'que', 'tu', 't', 'appelles', '?', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      "['comment', 'est', 'ce', 'que', 'tu', 't', 'appelles', '?', '<eos>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n"
     ]
    }
   ],
   "source": [
    "# 랜덤 시퀀스를 데이터셋의 순서로 지정\n",
    "print([index_to_src[word] for word in encoder_input[30997]])\n",
    "print([index_to_tar[word] for word in decoder_input[30997]])\n",
    "print([index_to_tar[word] for word in decoder_target[30997]])\n",
    "\n",
    "encoder_input = encoder_input[indices]\n",
    "decoder_input = decoder_input[indices]\n",
    "decoder_target = decoder_target[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1d027949-740d-4f27-b82f-edfa4f9ac9eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['we', 'have', 'a', 'problem', '.', '<PAD>', '<PAD>']\n",
      "['<sos>', 'nous', 'avons', 'un', 'probleme', '.', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      "['nous', 'avons', 'un', 'probleme', '.', '<eos>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n"
     ]
    }
   ],
   "source": [
    "print([index_to_src[word] for word in encoder_input[30997]])\n",
    "print([index_to_tar[word] for word in decoder_input[30997]])\n",
    "print([index_to_tar[word] for word in decoder_target[30997]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "412d8654-f3fb-450e-8beb-172e58b263d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "검증 데이터의 개수 : 3300\n"
     ]
    }
   ],
   "source": [
    "# 10% 에 해당하는 데이터를 테스트 데이터로 사용\n",
    "n_of_val = int(33000*0.1)\n",
    "print('검증 데이터의 개수 :',n_of_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1f9362eb-480f-451c-80bf-c9d08d1684df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train, test 분리\n",
    "encoder_input_train = encoder_input[:-n_of_val]\n",
    "decoder_input_train = decoder_input[:-n_of_val]\n",
    "decoder_target_train = decoder_target[:-n_of_val]\n",
    "\n",
    "encoder_input_test = encoder_input[-n_of_val:]\n",
    "decoder_input_test = decoder_input[-n_of_val:]\n",
    "decoder_target_test = decoder_target[-n_of_val:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f0de9843-5fa5-4630-a16e-d90d4f0205c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 source 데이터의 크기 : (29700, 7)\n",
      "훈련 target 데이터의 크기 : (29700, 16)\n",
      "훈련 target 레이블의 크기 : (29700, 16)\n",
      "테스트 source 데이터의 크기 : (3300, 7)\n",
      "테스트 target 데이터의 크기 : (3300, 16)\n",
      "테스트 target 레이블의 크기 : (3300, 16)\n"
     ]
    }
   ],
   "source": [
    "print('훈련 source 데이터의 크기 :',encoder_input_train.shape)\n",
    "print('훈련 target 데이터의 크기 :',decoder_input_train.shape)\n",
    "print('훈련 target 레이블의 크기 :',decoder_target_train.shape)\n",
    "print('테스트 source 데이터의 크기 :',encoder_input_test.shape)\n",
    "print('테스트 target 데이터의 크기 :',decoder_input_test.shape)\n",
    "print('테스트 target 레이블의 크기 :',decoder_target_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceafbb19-1da8-4080-bc6b-83959f75a5b8",
   "metadata": {},
   "source": [
    "# 기계 번역기 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e6a31bd8-170d-49c4-b250-94c8856a5232",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "embedding_dim = 256\n",
    "hidden_units = 256\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, src_vocab_size, embedding_dim, hidden_units):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.embedding = nn.Embedding(src_vocab_size, embedding_dim, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_units, batch_first=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x.shape == (batch_size, seq_len, embedding_dim)\n",
    "        x = self.embedding(x)\n",
    "        # hidden.shape == (1, batch_size, hidden_units), cell.shape == (1, batch_size, hidden_units)\n",
    "        _, (hidden, cell) = self.lstm(x)\n",
    "        # 인코더의 출력은 hidden state, cell state\n",
    "        return hidden, cell\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, tar_vocab_size, embedding_dim, hidden_units):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.embedding = nn.Embedding(tar_vocab_size, embedding_dim, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_units, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_units, tar_vocab_size)\n",
    "\n",
    "    def forward(self, x, hidden, cell):\n",
    "\n",
    "        # x.shape == (batch_size, seq_len, embedding_dim)\n",
    "        x = self.embedding(x)\n",
    "\n",
    "        # 디코더의 LSTM으로 인코더의 hidden state, cell state를 전달.\n",
    "        # output.shape == (batch_size, seq_len, hidden_units)\n",
    "        # hidden.shape == (1, batch_size, hidden_units)\n",
    "        # cell.shape == (1, batch_size, hidden_units)\n",
    "        output, (hidden, cell) = self.lstm(x, (hidden, cell))\n",
    "\n",
    "        # output.shape: (batch_size, seq_len, tar_vocab_size)\n",
    "        output = self.fc(output)\n",
    "\n",
    "        # 디코더의 출력은 예측값, hidden state, cell state\n",
    "        return output, hidden, cell\n",
    "\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, src, trg):\n",
    "        hidden, cell = self.encoder(src)\n",
    "\n",
    "        # 훈련 중에는 디코더의 출력 중 오직 output만 사용한다.\n",
    "        output, _, _ = self.decoder(trg, hidden, cell)\n",
    "        return output\n",
    "\n",
    "encoder = Encoder(src_vocab_size, embedding_dim, hidden_units)\n",
    "decoder = Decoder(tar_vocab_size, embedding_dim, hidden_units)\n",
    "model = Seq2Seq(encoder, decoder)\n",
    "\n",
    "loss_function = nn.CrossEntropyLoss(ignore_index=0)\n",
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "91cf9036-4064-4431-8c4f-e4d41d8c3a22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seq2Seq(\n",
      "  (encoder): Encoder(\n",
      "    (embedding): Embedding(4486, 256, padding_idx=0)\n",
      "    (lstm): LSTM(256, 256, batch_first=True)\n",
      "  )\n",
      "  (decoder): Decoder(\n",
      "    (embedding): Embedding(7879, 256, padding_idx=0)\n",
      "    (lstm): LSTM(256, 256, batch_first=True)\n",
      "    (fc): Linear(in_features=256, out_features=7879, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1766e15-036b-4bb6-ad80-16ec55931b8d",
   "metadata": {},
   "source": [
    "## Encoder\n",
    "Encoder 클래스는 입력 시퀀스를 받아 해당 시퀀스의 정보를 압축하여 context vector로 변환하는 역할\\\n",
    "Encoder는 임베딩 레이어와 LSTM 레이어로 구성\\\n",
    "임베딩 레이어는 입력 시퀀스의 각 토큰을 고정 크기의 벡터로 변환하고, LSTM 레이어는 시퀀스의 순서 정보를 고려하여 해당 시퀀스를 요약\\\n",
    "Encoder의 forward 메서드는 입력 시퀀스를 받아 LSTM의 hidden state와 cell state를 반환\n",
    "\n",
    "## Decoder\n",
    "Encoder에서 생성된 context vector(인코더의 마지막 은닉 상태)를 기반으로 출력 시퀀스를 생성하는 역할\\\n",
    "Decoder 또한 임베딩 레이어와 LSTM 레이어로 구성\\\n",
    "LSTM은 Encoder에서 전달받은 hidden state와 cell state를 초기 상태로 사용하여 출력 시퀀스를 생성\\\n",
    "생성된 출력 시퀀스는 fully connected 레이어를 통과하여 각 시점의 출력 토큰에 대한 확률 분포를 얻음\\\n",
    "Decoder의 forward 메서드는 입력 시퀀스, hidden state, cell state를 받아 출력 시퀀스, 업데이트된 hidden state와 cell state를 반환\n",
    "\n",
    "## Seq2Seq\n",
    "Encoder와 Decoder를 결합하여 전체 모델을 구성\\\n",
    "Seq2Seq 모델의 forward 메서드는 입력 시퀀스(src)와 출력 시퀀스(trg)를 받아 Encoder에서 생성된 은닉 상태(hidden state)와 셀 상태(cell state)를 Decoder로 전달\\\n",
    "Decoder에서 생성된 출력 시퀀스를 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "33ef8c44-8e32-4d30-a309-9e1075921d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "평가 함수\n",
    "\"\"\"\n",
    "def evaluation(model, dataloader, loss_function, device):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    total_correct = 0\n",
    "    total_count = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for encoder_inputs, decoder_inputs, decoder_targets in dataloader:\n",
    "            encoder_inputs = encoder_inputs.to(device)\n",
    "            decoder_inputs = decoder_inputs.to(device)\n",
    "            decoder_targets = decoder_targets.to(device)\n",
    "\n",
    "            # 순방향 전파\n",
    "            # outputs.shape == (batch_size, seq_len, tar_vocab_size)\n",
    "            outputs = model(encoder_inputs, decoder_inputs)\n",
    "\n",
    "            # 손실 계산\n",
    "            # outputs.view(-1, outputs.size(-1))의 shape는 (batch_size * seq_len, tar_vocab_size)\n",
    "            # decoder_targets.view(-1)의 shape는 (batch_size * seq_len)\n",
    "            loss = loss_function(outputs.view(-1, outputs.size(-1)), decoder_targets.view(-1))\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # 정확도 계산 (패딩 토큰 제외)\n",
    "            mask = decoder_targets != 0\n",
    "            total_correct += ((outputs.argmax(dim=-1) == decoder_targets) * mask).sum().item()\n",
    "            total_count += mask.sum().item()\n",
    "\n",
    "    return total_loss / len(dataloader), total_correct / total_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f819a09f-bfec-4678-811d-c68713d497a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 데이터셋과 테스트 데이터셋의 인코더 입력, 디코더 입력, 디코더 타겟을 PyTorch 텐서로 변환\n",
    "encoder_input_train_tensor = torch.tensor(encoder_input_train, dtype=torch.long)\n",
    "decoder_input_train_tensor = torch.tensor(decoder_input_train, dtype=torch.long)\n",
    "decoder_target_train_tensor = torch.tensor(decoder_target_train, dtype=torch.long)\n",
    "\n",
    "encoder_input_test_tensor = torch.tensor(encoder_input_test, dtype=torch.long)\n",
    "decoder_input_test_tensor = torch.tensor(decoder_input_test, dtype=torch.long)\n",
    "decoder_target_test_tensor = torch.tensor(decoder_target_test, dtype=torch.long)\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "# TensorDataset을 사용하여 학습 데이터셋과 테스트 데이터셋을 생성 - TensorDataset은 텐서들을 묶어서 데이터셋으로 만들어주는 역할을 함\n",
    "train_dataset = TensorDataset(encoder_input_train_tensor, decoder_input_train_tensor, decoder_target_train_tensor)\n",
    "# DataLoader를 사용하여 학습 데이터로더와 테스트 데이터로더를 생성\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "valid_dataset = TensorDataset(encoder_input_test_tensor, decoder_input_test_tensor, decoder_target_test_tensor)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c2ea3928-8b1f-45e4-b1c7-e0f2630c53a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Train Dataset:\")\n",
    "# for i in range(5):\n",
    "#     encoder_input, decoder_input, decoder_target = train_dataset[i]\n",
    "#     print(f\"Sample {i}:\")\n",
    "#     print(\" Encoder Input:\", encoder_input.numpy())\n",
    "#     print(\" Decoder Input:\", decoder_input.numpy())\n",
    "#     print(\" Decoder Target:\", decoder_target.numpy())\n",
    "# print()\n",
    "\n",
    "# # train_dataloader의 내용을 출력\n",
    "# print(\"Train DataLoader:\")\n",
    "# for batch_idx, (encoder_inputs, decoder_inputs, decoder_targets) in enumerate(train_dataloader):\n",
    "#     print(f\"Batch {batch_idx}:\")\n",
    "#     print(\" Encoder Inputs:\\n\", encoder_inputs.numpy())\n",
    "#     print(\" Decoder Inputs:\\n\", decoder_inputs.numpy())\n",
    "#     print(\" Decoder Targets:\\n\", decoder_targets.numpy())\n",
    "#     if batch_idx == 1:  # 두 번째 배치까지만 출력\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d3a4aea6-b852-4aa6-9ea1-41937c500a09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/30 | Train Loss: 2.9070 | Train Acc: 0.5310 | Valid Loss: 3.0286 | Valid Acc: 0.5274\n",
      "Validation loss improved from inf to 3.0286. 체크포인트를 저장합니다.\n",
      "Epoch: 2/30 | Train Loss: 2.2600 | Train Acc: 0.6038 | Valid Loss: 2.4958 | Valid Acc: 0.5927\n",
      "Validation loss improved from 3.0286 to 2.4958. 체크포인트를 저장합니다.\n",
      "Epoch: 3/30 | Train Loss: 1.8520 | Train Acc: 0.6480 | Valid Loss: 2.2066 | Valid Acc: 0.6242\n",
      "Validation loss improved from 2.4958 to 2.2066. 체크포인트를 저장합니다.\n",
      "Epoch: 4/30 | Train Loss: 1.5498 | Train Acc: 0.6798 | Valid Loss: 2.0269 | Valid Acc: 0.6420\n",
      "Validation loss improved from 2.2066 to 2.0269. 체크포인트를 저장합니다.\n",
      "Epoch: 5/30 | Train Loss: 1.2949 | Train Acc: 0.7239 | Valid Loss: 1.8827 | Valid Acc: 0.6626\n",
      "Validation loss improved from 2.0269 to 1.8827. 체크포인트를 저장합니다.\n",
      "Epoch: 6/30 | Train Loss: 1.0829 | Train Acc: 0.7582 | Valid Loss: 1.7760 | Valid Acc: 0.6797\n",
      "Validation loss improved from 1.8827 to 1.7760. 체크포인트를 저장합니다.\n",
      "Epoch: 7/30 | Train Loss: 0.9258 | Train Acc: 0.7811 | Valid Loss: 1.7223 | Valid Acc: 0.6845\n",
      "Validation loss improved from 1.7760 to 1.7223. 체크포인트를 저장합니다.\n",
      "Epoch: 8/30 | Train Loss: 0.7582 | Train Acc: 0.8244 | Valid Loss: 1.6283 | Valid Acc: 0.6988\n",
      "Validation loss improved from 1.7223 to 1.6283. 체크포인트를 저장합니다.\n",
      "Epoch: 9/30 | Train Loss: 0.6375 | Train Acc: 0.8525 | Valid Loss: 1.5868 | Valid Acc: 0.7068\n",
      "Validation loss improved from 1.6283 to 1.5868. 체크포인트를 저장합니다.\n",
      "Epoch: 10/30 | Train Loss: 0.5322 | Train Acc: 0.8729 | Valid Loss: 1.5563 | Valid Acc: 0.7117\n",
      "Validation loss improved from 1.5868 to 1.5563. 체크포인트를 저장합니다.\n",
      "Epoch: 11/30 | Train Loss: 0.4520 | Train Acc: 0.8869 | Valid Loss: 1.5387 | Valid Acc: 0.7140\n",
      "Validation loss improved from 1.5563 to 1.5387. 체크포인트를 저장합니다.\n",
      "Epoch: 12/30 | Train Loss: 0.3942 | Train Acc: 0.8987 | Valid Loss: 1.5295 | Valid Acc: 0.7182\n",
      "Validation loss improved from 1.5387 to 1.5295. 체크포인트를 저장합니다.\n",
      "Epoch: 13/30 | Train Loss: 0.3416 | Train Acc: 0.9076 | Valid Loss: 1.5269 | Valid Acc: 0.7189\n",
      "Validation loss improved from 1.5295 to 1.5269. 체크포인트를 저장합니다.\n",
      "Epoch: 14/30 | Train Loss: 0.3058 | Train Acc: 0.9132 | Valid Loss: 1.5324 | Valid Acc: 0.7208\n",
      "Epoch: 15/30 | Train Loss: 0.2749 | Train Acc: 0.9183 | Valid Loss: 1.5356 | Valid Acc: 0.7204\n",
      "Epoch: 16/30 | Train Loss: 0.2531 | Train Acc: 0.9211 | Valid Loss: 1.5431 | Valid Acc: 0.7207\n",
      "Epoch: 17/30 | Train Loss: 0.2337 | Train Acc: 0.9240 | Valid Loss: 1.5517 | Valid Acc: 0.7221\n",
      "Epoch: 18/30 | Train Loss: 0.2202 | Train Acc: 0.9260 | Valid Loss: 1.5730 | Valid Acc: 0.7208\n",
      "Epoch: 19/30 | Train Loss: 0.2078 | Train Acc: 0.9274 | Valid Loss: 1.5850 | Valid Acc: 0.7222\n",
      "Epoch: 20/30 | Train Loss: 0.1985 | Train Acc: 0.9282 | Valid Loss: 1.5943 | Valid Acc: 0.7218\n",
      "Epoch: 21/30 | Train Loss: 0.1910 | Train Acc: 0.9292 | Valid Loss: 1.6054 | Valid Acc: 0.7228\n",
      "Epoch: 22/30 | Train Loss: 0.1837 | Train Acc: 0.9306 | Valid Loss: 1.6159 | Valid Acc: 0.7222\n",
      "Epoch: 23/30 | Train Loss: 0.1809 | Train Acc: 0.9307 | Valid Loss: 1.6285 | Valid Acc: 0.7220\n",
      "Epoch: 24/30 | Train Loss: 0.1737 | Train Acc: 0.9311 | Valid Loss: 1.6367 | Valid Acc: 0.7232\n",
      "Epoch: 25/30 | Train Loss: 0.1712 | Train Acc: 0.9311 | Valid Loss: 1.6503 | Valid Acc: 0.7214\n",
      "Epoch: 26/30 | Train Loss: 0.1654 | Train Acc: 0.9321 | Valid Loss: 1.6572 | Valid Acc: 0.7215\n",
      "Epoch: 27/30 | Train Loss: 0.1647 | Train Acc: 0.9321 | Valid Loss: 1.6657 | Valid Acc: 0.7216\n",
      "Epoch: 28/30 | Train Loss: 0.1626 | Train Acc: 0.9322 | Valid Loss: 1.6859 | Valid Acc: 0.7212\n",
      "Epoch: 29/30 | Train Loss: 0.1588 | Train Acc: 0.9323 | Valid Loss: 1.6853 | Valid Acc: 0.7220\n",
      "Epoch: 30/30 | Train Loss: 0.1580 | Train Acc: 0.9323 | Valid Loss: 1.6941 | Valid Acc: 0.7204\n"
     ]
    }
   ],
   "source": [
    "# 학습 설정\n",
    "num_epochs = 30\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Training loop\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # 훈련 모드\n",
    "    model.train()\n",
    "\n",
    "    for encoder_inputs, decoder_inputs, decoder_targets in train_dataloader:\n",
    "        encoder_inputs = encoder_inputs.to(device)\n",
    "        decoder_inputs = decoder_inputs.to(device)\n",
    "        decoder_targets = decoder_targets.to(device)\n",
    "\n",
    "        # 기울기 초기화\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 순방향 전파\n",
    "        # outputs.shape == (batch_size, seq_len, tar_vocab_size)\n",
    "        outputs = model(encoder_inputs, decoder_inputs)\n",
    "\n",
    "        # 손실 계산 및 역방향 전파\n",
    "        # outputs.view(-1, outputs.size(-1))의 shape는 (batch_size * seq_len, tar_vocab_size)\n",
    "        # decoder_targets.view(-1)의 shape는 (batch_size * seq_len)\n",
    "        loss = loss_function(outputs.view(-1, outputs.size(-1)), decoder_targets.view(-1))\n",
    "        loss.backward()\n",
    "\n",
    "        # 가중치 업데이트\n",
    "        optimizer.step()\n",
    "\n",
    "    train_loss, train_acc = evaluation(model, train_dataloader, loss_function, device)\n",
    "    valid_loss, valid_acc = evaluation(model, valid_dataloader, loss_function, device)\n",
    "\n",
    "    print(f'Epoch: {epoch+1}/{num_epochs} | Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f} | Valid Loss: {valid_loss:.4f} | Valid Acc: {valid_acc:.4f}')\n",
    "\n",
    "    # 검증 손실이 최소일 때 체크포인트 저장\n",
    "    if valid_loss < best_val_loss:\n",
    "        print(f'Validation loss improved from {best_val_loss:.4f} to {valid_loss:.4f}. 체크포인트를 저장합니다.')\n",
    "        best_val_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'best_model_checkpoint.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "585bc819-d704-4c68-841d-cc18d55b160a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amps\\AppData\\Local\\Temp\\ipykernel_1944\\2929441124.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('best_model_checkpoint.pth'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model validation loss: 1.5269\n",
      "Best model validation accuracy: 0.7189\n"
     ]
    }
   ],
   "source": [
    "# 모델 로드\n",
    "model.load_state_dict(torch.load('best_model_checkpoint.pth'))\n",
    "\n",
    "# 모델을 device에 올립니다.\n",
    "model.to(device)\n",
    "\n",
    "# 검증 데이터에 대한 정확도와 손실 계산\n",
    "val_loss, val_accuracy = evaluation(model, valid_dataloader, loss_function, device)\n",
    "\n",
    "print(f'Best model validation loss: {val_loss:.4f}')\n",
    "print(f'Best model validation accuracy: {val_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a0b31054-e2d7-4b4d-8c35-888d1d961db6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "# <sos>와 <eos> 토큰의 정수는 각각 3과 4\n",
    "print(tar_vocab['<sos>'])\n",
    "print(tar_vocab['<eos>'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4578cc1e-3845-4a45-a020-f82b38aa27d6",
   "metadata": {},
   "source": [
    "# seq2seq 기계 번역기 동작시키기\n",
    "\n",
    "seq2seq는 훈련 과정(교사 강요)과 테스트 과정에서의 동작 방식이 다릅니다. 그래서 테스트 과정을 위해 모델을 다시 설계해주어야 합니다. 특히 디코더를 수정해야 합니다. 이번에는 번역 단계를 위해 모델을 수정하고 동작시켜보겠습니다.\n",
    "\n",
    "전체적인 번역 단계를 정리하면 아래와 같습니다.\n",
    "\n",
    "1) 번역하고자 하는 입력 문장이 인코더로 입력되어 인코더의 마지막 시점의 은닉 상태와 셀 상태를 얻습니다.\n",
    "2) 인코더의 은닉 상태와 셀 상태, 그리고 토큰 <sos>를 디코더로 보냅니다.\n",
    "3) 디코더가 토큰 <eos>가 나올 때까지 다음 단어를 예측하는 행동을 반복합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "eae0bad7-d051-4de4-85cc-915b8d75ec0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  3  13  10 366 215   2   0]\n",
      "[  3   5  22  25 234 415   2   0   0   0   0   0   0   0   0   0]\n",
      "[  5  22  25 234 415   2   4   0   0   0   0   0   0   0   0   0]\n"
     ]
    }
   ],
   "source": [
    "index_to_src = {v: k for k, v in src_vocab.items()}\n",
    "index_to_tar = {v: k for k, v in tar_vocab.items()}\n",
    "\n",
    "# 원문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
    "def seq_to_src(input_seq):\n",
    "    sentence = ''\n",
    "    for encoded_word in input_seq:\n",
    "        if(encoded_word != 0):\n",
    "            sentence = sentence + index_to_src[encoded_word] + ' '\n",
    "    return sentence\n",
    "\n",
    "# 번역문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
    "def seq_to_tar(input_seq):\n",
    "    sentence = ''\n",
    "    for encoded_word in input_seq:\n",
    "        if(encoded_word != 0 and encoded_word != tar_vocab['<sos>'] and encoded_word != tar_vocab['<eos>']):\n",
    "            sentence = sentence + index_to_tar[encoded_word] + ' '\n",
    "    return sentence\n",
    "\n",
    "print(encoder_input_test[25])\n",
    "print(decoder_input_test[25])\n",
    "print(decoder_target_test[25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9e1b24f2-f031-418f-8174-076372cbf9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq, model, src_vocab_size, tar_vocab_size, max_output_len, int_to_src_token, int_to_tar_token):\n",
    "    encoder_inputs = torch.tensor(input_seq, dtype=torch.long).unsqueeze(0).to(device)\n",
    "\n",
    "    # 인코더의 초기 상태 설정\n",
    "    hidden, cell = model.encoder(encoder_inputs)\n",
    "\n",
    "    # 시작 토큰 <sos>을 디코더의 첫 입력으로 설정\n",
    "    # unsqueeze(0)는 배치 차원을 추가하기 위함.\n",
    "    decoder_input = torch.tensor([3], dtype=torch.long).unsqueeze(0).to(device)\n",
    "\n",
    "    decoded_tokens = []\n",
    "\n",
    "    # for문을 도는 것 == 디코더의 각 시점\n",
    "    for _ in range(max_output_len):\n",
    "        output, hidden, cell = model.decoder(decoder_input, hidden, cell)\n",
    "\n",
    "        # 소프트맥스 회귀를 수행. 예측 단어의 인덱스\n",
    "        output_token = output.argmax(dim=-1).item()\n",
    "\n",
    "        # 종료 토큰 <eos>\n",
    "        if output_token == 4:\n",
    "            break\n",
    "\n",
    "        # 각 시점의 단어(정수)는 decoded_tokens에 누적하였다가 최종 번역 시퀀스로 리턴합니다.\n",
    "        decoded_tokens.append(output_token)\n",
    "\n",
    "        # 현재 시점의 예측. 다음 시점의 입력으로 사용된다.\n",
    "        decoder_input = torch.tensor([output_token], dtype=torch.long).unsqueeze(0).to(device)\n",
    "\n",
    "    return ' '.join(int_to_tar_token[token] for token in decoded_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ba0d737d-93b2-4d29-b206-699fa1f878f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력문장 : are you productive ? \n",
      "정답문장 : etes vous productifs ? \n",
      "번역문장 : etes vous productif ?\n",
      "--------------------------------------------------\n",
      "입력문장 : i didn t see much . \n",
      "정답문장 : je n ai pas vu grand chose . \n",
      "번역문장 : je ne l ai pas vu .\n",
      "--------------------------------------------------\n",
      "입력문장 : you can go now . \n",
      "정답문장 : tu peux partir maintenant . \n",
      "번역문장 : tu peux partir maintenant .\n",
      "--------------------------------------------------\n",
      "입력문장 : it s very nice . \n",
      "정답문장 : c est tres gentil . \n",
      "번역문장 : c est tres gentil .\n",
      "--------------------------------------------------\n",
      "입력문장 : be nice to her . \n",
      "정답문장 : sois gentil avec elle . \n",
      "번역문장 : sois gentil avec elle !\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#  훈련 데이터에 대해서 임의로 선택한 인덱스의 샘플의 결과를 출력\n",
    "for seq_index in [3, 50, 100, 300, 1001]:\n",
    "    input_seq = encoder_input_train[seq_index]\n",
    "    translated_text = decode_sequence(input_seq, model, src_vocab_size, tar_vocab_size, 20, index_to_src, index_to_tar)\n",
    "\n",
    "    print(\"입력문장 :\",seq_to_src(encoder_input_train[seq_index]))\n",
    "    print(\"정답문장 :\",seq_to_tar(decoder_input_train[seq_index]))\n",
    "    print(\"번역문장 :\",translated_text)\n",
    "    print(\"-\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f55d4205-2a86-442c-b6b5-8a2952a926bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력문장 : who s in control ? \n",
      "정답문장 : qui est aux commandes ? \n",
      "번역문장 : qui est en train de la faute ?\n",
      "--------------------------------------------------\n",
      "입력문장 : is this lake deep ? \n",
      "정답문장 : est ce que ce lac est profond ? \n",
      "번역문장 : c est vrai ?\n",
      "--------------------------------------------------\n",
      "입력문장 : that ll end badly . \n",
      "정답문장 : ca va mal tourner . \n",
      "번역문장 : ca finira mal .\n",
      "--------------------------------------------------\n",
      "입력문장 : i m speaking . \n",
      "정답문장 : je suis en train de parler . \n",
      "번역문장 : je suis .\n",
      "--------------------------------------------------\n",
      "입력문장 : hold on a minute . \n",
      "정답문장 : attendez une minute ! \n",
      "번역문장 : attends voir !\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 테스트 데이터에 대해서 임의로 선택한 인덱스의 샘플의 결과 출력\n",
    "for seq_index in [3, 50, 100, 300, 1001]:\n",
    "    input_seq = encoder_input_test[seq_index]\n",
    "    translated_text = decode_sequence(input_seq, model, src_vocab_size, tar_vocab_size, 20, index_to_src, index_to_tar)\n",
    "\n",
    "    print(\"입력문장 :\",seq_to_src(encoder_input_test[seq_index]))\n",
    "    print(\"정답문장 :\",seq_to_tar(decoder_input_test[seq_index]))\n",
    "    print(\"번역문장 :\",translated_text)\n",
    "    print(\"-\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf91d2b-0e86-4d25-b47d-f39299b8fb5d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl-study",
   "language": "python",
   "name": "dl-study"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
