{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f46793af-c2c5-4464-a46b-19429ff49f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 로드를 위함\n",
    "from datasets import load_dataset\n",
    "\n",
    "# 기본 파이썬 패키지\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "from tqdm import tqdm\n",
    "\n",
    "# GPT 사용을 위함\n",
    "import torch\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import BertTokenizer\n",
    "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "# for padding\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# 전처리 및 평가 지표\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, roc_auc_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "319a1f50-4ce4-4dd6-9788-43d542edccbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100% [..........................................................................] 1319001 / 1319001"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'finance_data (1).csv'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wget\n",
    "url= 'https://raw.githubusercontent.com/ukairia777/finance_sentiment_corpus/main/finance_data.csv'\n",
    "wget.download(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1288a5a-e443-4ef0-925e-4c79f3efae30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "샘플의 개수 : 4846\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('finance_data.csv')\n",
    "print('샘플의 개수 :', len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3436e3f2-0ffe-4142-badf-aa61215fd3de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>sentence</th>\n",
       "      <th>kor_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>According to Gran, the company has no plans to...</td>\n",
       "      <td>Gran에 따르면, 그 회사는 회사가 성장하고 있는 곳이지만, 모든 생산을 러시아로...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Technopolis plans to develop in stages an area...</td>\n",
       "      <td>테크노폴리스는 컴퓨터 기술과 통신 분야에서 일하는 회사들을 유치하기 위해 10만 평...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>The international electronic industry company ...</td>\n",
       "      <td>국제 전자산업 회사인 엘코텍은 탈린 공장에서 수십 명의 직원을 해고했으며, 이전의 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>With the new production plant the company woul...</td>\n",
       "      <td>새로운 생산공장으로 인해 회사는 예상되는 수요 증가를 충족시킬 수 있는 능력을 증가...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>According to the company's updated strategy fo...</td>\n",
       "      <td>2009-2012년 회사의 업데이트된 전략에 따르면, Basware는 20% - 4...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   labels                                           sentence  \\\n",
       "0       0  According to Gran, the company has no plans to...   \n",
       "1       0  Technopolis plans to develop in stages an area...   \n",
       "2       2  The international electronic industry company ...   \n",
       "3       1  With the new production plant the company woul...   \n",
       "4       1  According to the company's updated strategy fo...   \n",
       "\n",
       "                                        kor_sentence  \n",
       "0  Gran에 따르면, 그 회사는 회사가 성장하고 있는 곳이지만, 모든 생산을 러시아로...  \n",
       "1  테크노폴리스는 컴퓨터 기술과 통신 분야에서 일하는 회사들을 유치하기 위해 10만 평...  \n",
       "2  국제 전자산업 회사인 엘코텍은 탈린 공장에서 수십 명의 직원을 해고했으며, 이전의 ...  \n",
       "3  새로운 생산공장으로 인해 회사는 예상되는 수요 증가를 충족시킬 수 있는 능력을 증가...  \n",
       "4  2009-2012년 회사의 업데이트된 전략에 따르면, Basware는 20% - 4...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "008f5c5a-7137-4c20-adb1-dee38908654e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "labels\n",
       "0    2879\n",
       "1    1363\n",
       "2     604\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['labels'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "362d5158-2092-41a9-b8e4-d24db6fc508a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>sentence</th>\n",
       "      <th>kor_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>According to Gran, the company has no plans to...</td>\n",
       "      <td>Gran에 따르면, 그 회사는 회사가 성장하고 있는 곳이지만, 모든 생산을 러시아로...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Technopolis plans to develop in stages an area...</td>\n",
       "      <td>테크노폴리스는 컴퓨터 기술과 통신 분야에서 일하는 회사들을 유치하기 위해 10만 평...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>The international electronic industry company ...</td>\n",
       "      <td>국제 전자산업 회사인 엘코텍은 탈린 공장에서 수십 명의 직원을 해고했으며, 이전의 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>With the new production plant the company woul...</td>\n",
       "      <td>새로운 생산공장으로 인해 회사는 예상되는 수요 증가를 충족시킬 수 있는 능력을 증가...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>According to the company's updated strategy fo...</td>\n",
       "      <td>2009-2012년 회사의 업데이트된 전략에 따르면, Basware는 20% - 4...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   labels                                           sentence  \\\n",
       "0       0  According to Gran, the company has no plans to...   \n",
       "1       0  Technopolis plans to develop in stages an area...   \n",
       "2       2  The international electronic industry company ...   \n",
       "3       1  With the new production plant the company woul...   \n",
       "4       1  According to the company's updated strategy fo...   \n",
       "\n",
       "                                        kor_sentence  \n",
       "0  Gran에 따르면, 그 회사는 회사가 성장하고 있는 곳이지만, 모든 생산을 러시아로...  \n",
       "1  테크노폴리스는 컴퓨터 기술과 통신 분야에서 일하는 회사들을 유치하기 위해 10만 평...  \n",
       "2  국제 전자산업 회사인 엘코텍은 탈린 공장에서 수십 명의 직원을 해고했으며, 이전의 ...  \n",
       "3  새로운 생산공장으로 인해 회사는 예상되는 수요 증가를 충족시킬 수 있는 능력을 증가...  \n",
       "4  2009-2012년 회사의 업데이트된 전략에 따르면, Basware는 20% - 4...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 레이블 인코딩\n",
    "df['labels'] = df['labels'].replace(['neutral', 'positive', 'negative'],[0, 1, 2])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed32fab4-acaa-4570-aee0-257834d07a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 값을 변경한 데이터프레임을 다시 csv로 저장\n",
    "df.to_csv('finance_data.csv', index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a9ee9acc-fa91-405e-9c60-c303100c9b6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94950147243a43539001dc55a9ac2021",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# csv 파일로부터 datasets 패키지의 load_dataset()를 이용하여 DatasetDict 객체 로드\n",
    "all_data = load_dataset(\"csv\", data_files={\"train\": \"finance_data.csv\", },)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ca48c24b-bb9b-4216-94d1-5dc8ec8412c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['labels', 'sentence', 'kor_sentence'],\n",
       "        num_rows: 4846\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "005a031c-db18-465d-a6d9-c4041118dc1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['labels', 'sentence', 'kor_sentence'],\n",
      "    num_rows: 3876\n",
      "})\n",
      "Dataset({\n",
      "    features: ['labels', 'sentence', 'kor_sentence'],\n",
      "    num_rows: 970\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# train/test 데이터 분할\n",
    "cs = all_data['train'].train_test_split(0.2, seed=777)\n",
    "train_cs = cs[\"train\"]\n",
    "test_cs = cs[\"test\"]\n",
    "\n",
    "print(train_cs)\n",
    "print(test_cs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dd552922-636c-4101-9aaa-f9a9f34e840c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련 데이터를 다시 8:2로 분리 후 훈련 데이터와 검증 데이터로 저장\n",
    "cs = train_cs.train_test_split(0.2, seed=777)\n",
    "train_cs = cs[\"train\"]\n",
    "valid_cs = cs[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "110b3213-c764-42c0-9999-1abf4661478d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['labels', 'sentence', 'kor_sentence'],\n",
       "    num_rows: 776\n",
       "})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_cs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7e2eb75c-7d3f-4a17-8e72-bf21bbbdcd84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "두번째 샘플 출력 : 이 솔루션은 이전에 Comptel과 IBM이 제공한 기존 온라인 중재 솔루션의 확장 버전입니다.\n",
      "두번째 샘플의 레이블 출력 : 0\n"
     ]
    }
   ],
   "source": [
    "# 임의로 훈련 데이터 1번 샘플을 출력\n",
    "print('두번째 샘플 출력 :', train_cs['kor_sentence'][1])\n",
    "print('두번째 샘플의 레이블 출력 :', train_cs['labels'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "32666dbc-df98-4240-a910-b5e36a53a64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련 데이터, 검증 데이터, 테스트 데이터\n",
    "train_sentences = list(train_cs['kor_sentence'])\n",
    "validation_sentences = list(valid_cs['kor_sentence'])\n",
    "test_sentences = list(test_cs['kor_sentence'])\n",
    "\n",
    "train_labels = train_cs['labels']\n",
    "validation_labels = valid_cs['labels']\n",
    "test_labels = test_cs['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "13927009-04b7-4b44-aa3e-551ad6495dd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['오전 10.58시 아우토쿰푸는 2.74pct 하락한 24.87유로, OMX 헬싱키 25지수는 0.55pct 상승한 2,825.14, OMX 헬싱키는 0.64pct 하락한 9,386.89유로에 거래됐다.', '10월부터 12월까지의 판매량은 302 mln 유로로 전년 동기 대비 25.3 pct 증가했다.', '매디슨, 위스콘신, 2월 6일 - PRNewswire - - 피스카스는 미국 특허청이 상징적인 가위 손잡이에 오렌지색 상표 등록을 허가했다고 발표한다.', \"M-real로 평가된 분석가들 중 총 6명은 ''매수' - ''누적''을 주었고, 3명은 ''보유'', 1명만이 ''매도''를 주었다.\", '주요 양조업체들은 지난해 국내 맥주 판매량을 2004년 2억4592만 리터에서 2억5688만 리터로 4.5% 늘렸다.']\n",
      "[0, 1, 1, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "print(test_sentences[:5])\n",
    "print(test_labels[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "794966b4-9b1c-4e0a-9423-e67527840b9d",
   "metadata": {},
   "source": [
    "# 3. GPT 토크나이저를 이용한 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d7e90603-a210-4c10-a703-9c0b538810d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amps\\anaconda3\\envs\\dl_study\\lib\\site-packages\\huggingface_hub\\file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "# 한국어 GPT 중 하나인 'skt/kogpt2-base-v2'를 사용.\n",
    "tokenizer = AutoTokenizer.from_pretrained('skt/kogpt2-base-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9df7da94-8956-42e7-9703-86f35c6e6f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최대 길이는 128\n",
    "max_len = 128\n",
    "\n",
    "def data_to_tensor (sentences, labels, MAX_LEN):\n",
    "    # 정수 인코딩 과정. 각 텍스트를 토큰화한 후에 Vocabulary에 맵핑되는 정수 시퀀스로 변환한다.\n",
    "    # ex) ['안녕하세요'] ==> ['안', '녕', '하세요'] ==> [231, 52, 45]\n",
    "    tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\n",
    "    input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n",
    "\n",
    "    # pad_sequences는 패딩을 위한 모듈. 주어진 최대 길이를 위해서 뒤에서 패딩 토큰의 번호로 채워준다.\n",
    "    # ex) [231, 52, 45] ==> [231, 52, 45, 패딩 토큰, 패딩 토큰, 패딩 토큰]\n",
    "    pad_token = tokenizer.encode('<pad>')[0]\n",
    "    input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, value=pad_token, dtype=\"long\", truncating=\"post\", padding=\"post\") \n",
    "\n",
    "    attention_masks = []\n",
    "\n",
    "    for seq in input_ids:\n",
    "        seq_mask = [float(i != pad_token) for i in seq]\n",
    "        attention_masks.append(seq_mask)\n",
    "\n",
    "    tensor_inputs = torch.tensor(input_ids)\n",
    "    tensor_labels = torch.tensor(labels)\n",
    "    tensor_masks = torch.tensor(attention_masks)\n",
    "\n",
    "    return tensor_inputs, tensor_labels, tensor_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "596e4248-2b9e-4db8-848a-f182036d365a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 데이터, 검증 데이터, 테스트 데이터에 대해서\n",
    "# 정수 인코딩 결과, 레이블, 어텐션 마스크를 각각 inputs, labels, masks에 저장.\n",
    "train_inputs, train_labels, train_masks = data_to_tensor(train_sentences, train_labels, max_len)\n",
    "validation_inputs, validation_labels, validation_masks = data_to_tensor(validation_sentences, validation_labels, max_len)\n",
    "test_inputs, test_labels, test_masks = data_to_tensor(test_sentences, test_labels, max_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "282f15e4-7948-4517-9219-32f4884574d8",
   "metadata": {},
   "source": [
    "# 4. 데이터의 배치화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f2740802-fce1-46d2-b51c-5470e3135ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "522420e8-2f60-48b9-b4f8-ee6ff8ddd460",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
    "validation_sampler = SequentialSampler(validation_data)\n",
    "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9cb1794b-4f86-4696-89e2-5a5c95608e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = TensorDataset(test_inputs, test_masks, test_labels)\n",
    "test_sampler = RandomSampler(test_data)\n",
    "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0428e24-8870-4412-adcb-7d4f588a3aa3",
   "metadata": {},
   "source": [
    "# 5. GPU가 정상 셋팅되었는지 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2f7ec67b-663d-4f1d-9b4f-dd28790bc467",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: NVIDIA GeForce RTX 4060 Ti\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print('No GPU available, using the CPU instead.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4502dd68-4bc0-4f45-b3db-2a9e0326aa30",
   "metadata": {},
   "source": [
    "# 6. 모델 로드하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8bdac522-3057-4bab-aa1f-cf30efcaa3c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amps\\anaconda3\\envs\\dl_study\\lib\\site-packages\\huggingface_hub\\file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\amps\\anaconda3\\envs\\dl_study\\lib\\site-packages\\transformers\\modeling_utils.py:446: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(checkpoint_file, map_location=\"cpu\")\n",
      "Some weights of the model checkpoint at skt/kogpt2-base-v2 were not used when initializing GPT2ForSequenceClassification: ['lm_head.weight']\n",
      "- This IS expected if you are initializing GPT2ForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing GPT2ForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at skt/kogpt2-base-v2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GPT2ForSequenceClassification(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(51200, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-11): 12 x GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (score): Linear(in_features=768, out_features=3, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_labels = 3\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"skt/kogpt2-base-v2\", num_labels=num_labels)\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b21033-a32f-41f2-b80c-a035d6cea8a5",
   "metadata": {},
   "source": [
    "# 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4b1edea8-5c45-4db2-85f7-7cd7bfe105bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amps\\anaconda3\\envs\\dl_study\\lib\\site-packages\\transformers\\optimization.py:407: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# 몇 번의 에포크(전체 데이터에 대한 학습 횟수)를 할 것인지 선택\n",
    "epochs = 3\n",
    "\n",
    "# 옵티마이저 선택\n",
    "optimizer = AdamW(model.parameters(), lr = 2e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5de63d75-efb8-4fb2-843e-8a0a7499d4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics(predictions, labels):\n",
    "    # predictions: 모델이 예측한 결과값들의 리스트 또는 배열\n",
    "    # labels: 실제 정답 레이블들의 리스트 또는 배열\n",
    "\n",
    "    # 예측값과 실제 레이블을 별도의 변수에 할당\n",
    "    y_pred = predictions\n",
    "    y_true = labels\n",
    "\n",
    "    # 사용 가능한 메트릭들을 계산\n",
    "\n",
    "    # 정확도 (Accuracy)\n",
    "    # 전체 예측 중에서 올바르게 예측한 비율\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "\n",
    "    # 매크로 평균 F1 점수 (Macro-averaged F1 Score)\n",
    "    # 클래스별로 F1 점수를 계산한 후, 그 평균을 구함\n",
    "    # zero_division=0 옵션은 분모가 0일 경우 0을 반환하도록 설정\n",
    "    f1_macro_average = f1_score(y_true=y_true, y_pred=y_pred, average='macro', zero_division=0)\n",
    "\n",
    "    # 마이크로 평균 F1 점수 (Micro-averaged F1 Score)\n",
    "    # 전체 데이터에 대해 단일 F1 점수를 계산\n",
    "    # 클래스 불균형이 심한 경우에 적합\n",
    "    f1_micro_average = f1_score(y_true=y_true, y_pred=y_pred, average='micro', zero_division=0)\n",
    "\n",
    "    # 가중 평균 F1 점수 (Weighted-averaged F1 Score)\n",
    "    # 각 클래스의 F1 점수에 해당 클래스의 샘플 수를 가중치로 곱한 후 평균을 구함\n",
    "    f1_weighted_average = f1_score(y_true=y_true, y_pred=y_pred, average='weighted', zero_division=0)\n",
    "\n",
    "    # 계산된 메트릭 결과를 딕셔너리 형태로 리턴\n",
    "    metrics = {'accuracy': accuracy,\n",
    "               'f1_macro': f1_macro_average,\n",
    "               'f1_micro': f1_micro_average,\n",
    "               'f1_weighted': f1_weighted_average}\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3ae26e8c-ffe7-4ee7-986b-234b2d15aa8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, train_dataloader, optimizer, device):\n",
    "    \"\"\"\n",
    "    하나의 에포크 동안 모델을 학습시키는 함수입니다.\n",
    "\n",
    "    Parameters:\n",
    "    model (torch.nn.Module): 학습시킬 모델 객체.\n",
    "    train_dataloader (torch.utils.data.DataLoader): 학습 데이터셋의 DataLoader.\n",
    "    optimizer (torch.optim.Optimizer): 최적화 알고리즘을 구현하는 객체.\n",
    "    device (torch.device): 학습에 사용할 장치(CPU 또는 CUDA).\n",
    "\n",
    "    Returns:\n",
    "    float: 평균 학습 손실값.\n",
    "    \"\"\"\n",
    "\n",
    "    total_train_loss = 0  # 학습 손실을 누적할 변수 초기화\n",
    "    model.train()  # 모델을 학습 모드로 설정\n",
    "\n",
    "    # 학습 데이터로더를 순회하며 배치 단위로 학습\n",
    "    for step, batch in tqdm(enumerate(train_dataloader), desc=\"Training Batch\"):\n",
    "        batch = tuple(t.to(device) for t in batch)  # DataLoader에서 배치를 받아 각 텐서를 지정된 장치로 이동\n",
    "        b_input_ids, b_input_mask, b_labels = batch  # 배치에서 입력 ID, 마스크, 라벨 추출\n",
    "\n",
    "        # 모델에 배치를 전달하여 손실값 계산\n",
    "        outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n",
    "\n",
    "        # 손실값 추출\n",
    "        loss = outputs.loss\n",
    "\n",
    "        optimizer.zero_grad()  # 기울기(gradient) 초기화\n",
    "        loss.backward()  # 역전파를 통해 기울기(gradient) 계산\n",
    "        optimizer.step()  # 매개변수 업데이트\n",
    "\n",
    "        total_train_loss += loss.item()  # 총 손실에 더함\n",
    "\n",
    "    avg_train_loss = total_train_loss / len(train_dataloader)  # 평균 학습 손실 계산\n",
    "\n",
    "    return avg_train_loss  # 평균 학습 손실 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "61983786-698d-4c8c-89bf-f5ebec231a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, validation_dataloader, device):\n",
    "    \"\"\"\n",
    "    모델을 사용하여 검증 데이터셋에 대한 평가를 수행하는 함수입니다.\n",
    "\n",
    "    Parameters:\n",
    "    model (torch.nn.Module): 평가할 모델 객체.\n",
    "    validation_dataloader (torch.utils.data.DataLoader): 검증 데이터셋의 DataLoader.\n",
    "    device (torch.device): 평가에 사용할 장치(CPU 또는 CUDA).\n",
    "\n",
    "    Returns:\n",
    "    float: 평균 검증 손실값.\n",
    "    dict: 다양한 평가 지표(metrics)에 대한 값들을 담은 사전.\n",
    "    \"\"\"\n",
    "\n",
    "    model.eval()  # 모델을 평가 모드로 설정\n",
    "\n",
    "    total_eval_loss = 0  # 검증 손실을 누적할 변수 초기화\n",
    "    predictions, true_labels = [], []  # 예측값과 실제 라벨값을 저장할 리스트 초기화\n",
    "\n",
    "    # 검증 데이터로더를 순회하며 배치 단위로 평가\n",
    "    for batch in validation_dataloader:\n",
    "        batch = tuple(t.to(device) for t in batch)  # 배치 데이터를 디바이스로 이동\n",
    "        b_input_ids, b_input_mask, b_labels = batch  # 배치에서 입력 ID, 마스크, 라벨 추출\n",
    "\n",
    "        with torch.no_grad():  # 기울기(gradient) 계산을 수행하지 않음\n",
    "            outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n",
    "\n",
    "        # 모델 출력에서 손실값 추출\n",
    "        if outputs.loss is not None:\n",
    "            loss = outputs.loss\n",
    "            total_eval_loss += loss.item()  # 총 손실에 더함\n",
    "\n",
    "        logits = outputs.logits.detach().cpu().numpy()  # 모델 예측값(로짓)을 numpy 배열로 변환\n",
    "        label_ids = b_labels.to('cpu').numpy()  # 실제 라벨값을 numpy 배열로 변환\n",
    "\n",
    "        # 3개의 값 중 가장 큰 값을 예측한 인덱스로 결정 (예시: logits = [3.513, -0.309, -2.111] ==> 예측: 0)\n",
    "        predictions.extend(np.argmax(logits, axis=1).flatten()) # 예측된 클래스를 리스트에 추가\n",
    "        true_labels.extend(label_ids.flatten()) # 실제 레이블 값을 리스트에 추가\n",
    "\n",
    "    eval_metrics = metrics(predictions, true_labels)\n",
    "\n",
    "    return total_eval_loss / len(validation_dataloader), eval_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2a661ff2-1666-4bd9-93dc-e291dfe2bdc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======== Epoch 1 / 3 ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batch: 122it [00:44,  2.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running Validation...\n",
      "  Validation Loss: 0.29\n",
      "  Accuracy: 0.89\n",
      "  F1 Macro: 0.86\n",
      "  F1 Micro: 0.89\n",
      "  F1 Weighted: 0.89\n",
      "Validation loss decreased (inf --> 0.29).  Saving model ...\n",
      "======== Epoch 2 / 3 ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batch: 122it [00:44,  2.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running Validation...\n",
      "  Validation Loss: 0.27\n",
      "  Accuracy: 0.89\n",
      "  F1 Macro: 0.89\n",
      "  F1 Micro: 0.89\n",
      "  F1 Weighted: 0.89\n",
      "Validation loss decreased (0.29 --> 0.27).  Saving model ...\n",
      "======== Epoch 3 / 3 ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batch: 122it [00:43,  2.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running Validation...\n",
      "  Validation Loss: 0.10\n",
      "  Accuracy: 0.98\n",
      "  F1 Macro: 0.97\n",
      "  F1 Micro: 0.98\n",
      "  F1 Weighted: 0.98\n",
      "Validation loss decreased (0.27 --> 0.10).  Saving model ...\n"
     ]
    }
   ],
   "source": [
    "# 최소 검증 손실 초기화\n",
    "min_val_loss = float('inf')\n",
    "\n",
    "# 메인 학습 & 평가 루프\n",
    "for epoch_i in range(0, epochs):\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "\n",
    "    # 학습 단계\n",
    "    train_epoch(model, train_dataloader, optimizer, device)\n",
    "\n",
    "    print(\"\\nRunning Validation...\")\n",
    "    # 검증 단계\n",
    "    avg_val_loss, eval_metrics = evaluate(model, validation_dataloader, device)\n",
    "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
    "    print(\"  Accuracy: {0:.2f}\".format(eval_metrics['accuracy']))\n",
    "    print(\"  F1 Macro: {0:.2f}\".format(eval_metrics['f1_macro']))\n",
    "    print(\"  F1 Micro: {0:.2f}\".format(eval_metrics['f1_micro']))\n",
    "    print(\"  F1 Weighted: {0:.2f}\".format(eval_metrics['f1_weighted']))\n",
    "\n",
    "    # 검증 손실이 현재까지의 최소값보다 작은 경우 체크포인트 저장\n",
    "    if avg_val_loss < min_val_loss:\n",
    "        print(f\"Validation loss decreased ({min_val_loss:.2f} --> {avg_val_loss:.2f}).  Saving model ...\")\n",
    "        # 베스트 모델 저장\n",
    "        torch.save(model.state_dict(), 'model_checkpoint.pt')\n",
    "        # 최소 검증 손실 업데이트\n",
    "        min_val_loss = avg_val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e50dbfb7-e8d3-4995-b184-38292258e1f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amps\\AppData\\Local\\Temp\\ipykernel_20584\\2468398973.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"model_checkpoint.pt\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Test Loss: 0.48\n",
      "  Accuracy: 0.81\n",
      "  F1 Macro: 0.81\n",
      "  F1 Micro: 0.81\n",
      "  F1 Weighted: 0.82\n"
     ]
    }
   ],
   "source": [
    "# 베스트 모델 로드\n",
    "model.load_state_dict(torch.load(\"model_checkpoint.pt\"))\n",
    "\n",
    "avg_val_loss, eval_metrics = evaluate(model, test_dataloader, device)\n",
    "print(\"  Test Loss: {0:.2f}\".format(avg_val_loss))\n",
    "print(\"  Accuracy: {0:.2f}\".format(eval_metrics['accuracy']))\n",
    "print(\"  F1 Macro: {0:.2f}\".format(eval_metrics['f1_macro']))\n",
    "print(\"  F1 Micro: {0:.2f}\".format(eval_metrics['f1_micro']))\n",
    "print(\"  F1 Weighted: {0:.2f}\".format(eval_metrics['f1_weighted']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "87ed7d4d-eceb-4fb4-9678-79f8ad0ab484",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amps\\anaconda3\\envs\\dl_study\\lib\\site-packages\\transformers\\pipelines\\text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar funcionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
      "  warnings.warn(\n",
      "Xformers is not installed correctly. If you want to use memorry_efficient_attention to accelerate training use the following command to install Xformers\n",
      "pip install xformers.\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"text-classification\", model=model.cuda(), tokenizer=tokenizer, device=0, max_length=512, return_all_scores=True, function_to_apply='softmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "459e6347-c68f-4b68-b354-046fe17e4ff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[{'label': 'LABEL_0', 'score': 0.035924702882766724}, {'label': 'LABEL_1', 'score': 0.9639436602592468}, {'label': 'LABEL_2', 'score': 0.00013158631918486208}]]\n"
     ]
    }
   ],
   "source": [
    "result = pipe('SK하이닉스가 매출이 급성장하였다')\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "eda38df2-fbb6-43f4-86e1-163eee97fea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'LABEL_1', 'score': 0.9639436602592468}]\n"
     ]
    }
   ],
   "source": [
    "# return_all_scores 제거\n",
    "pipe = pipeline(\"text-classification\", model=model.cuda(), tokenizer=tokenizer, device=0, max_length=512, function_to_apply='softmax')\n",
    "\n",
    "result = pipe('SK하이닉스가 매출이 급성장하였다')\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "2881d0d8-00b1-40b9-afd3-e83aaac59404",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dict = {'LABEL_0' : '중립', 'LABEL_1' : '긍정', 'LABEL_2' : '부정'}\n",
    "\n",
    "def prediction(text):\n",
    "    result = pipe(text)\n",
    "\n",
    "    return [label_dict[result[0]['label']]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "3e1a7cd3-5d1f-47a0-b8c6-467aa0670202",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['긍정']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction('네이버가 매출이 급성장하였다')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "55f153f8-4f1a-466a-81b8-311f15dbc08f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['부정']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction('ChatGPT의 등장으로 인공지능 스타트업들은 위기다')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ee8106a9-1ba7-4aae-9b67-5662d8fb8d92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['중립']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction('인공지능 기술의 발전으로 누군가는 기회를 얻을 것이고, 누군가는 얻지 못할 것이다')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e9ffa0-5fb0-400b-a644-570408ac29e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4927c557-d942-48e7-b36b-e21b0befe925",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5bc078-4b82-4902-a639-c09136bb2b8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a793a9-3bee-4d4d-b943-7149b4a4fa7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006064fa-1bb0-41b7-b49a-7367a36cb704",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8304522-41c4-4c10-8824-29f581d636a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_study",
   "language": "python",
   "name": "dl_study"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
