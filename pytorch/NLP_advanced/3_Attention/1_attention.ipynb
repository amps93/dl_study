{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63a8840e-fd03-41a8-877f-e88e25f769e7",
   "metadata": {},
   "source": [
    "RNN에 기반한 seq2seq 모델에는 크게 두 가지 문제가 있습니다.\\\n",
    "첫째, 하나의 고정된 크기의 벡터에 모든 정보를 압축하려고 하니까 정보 손실이 발생합니다.\\\n",
    "둘째, RNN의 고질적인 문제인 기울기 소실(vanishing gradient) 문제가 존재합니다.\\\n",
    "\n",
    "\n",
    "## 1. 어텐션(Attention)의 아이디어\n",
    "어텐션의 기본 아이디어는 디코더에서 출력 단어를 예측하는 매 시점(time step)마다, 인코더에서의 전체 입력 문장을 다시 한 번 참고한다는 점입니다. \\\n",
    "단, 전체 입력 문장을 전부 다 동일한 비율로 참고하는 것이 아니라, <b>해당 시점에서 예측해야할 단어와 연관이 있는 입력 단어 부분을 좀 더 집중(attention)</b>해서 보게 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af8faf91-0510-4abc-a1fd-35cda6274cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import unicodedata\n",
    "import urllib3\n",
    "import zipfile\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "626c71bc-aa98-4291-b575-93f013ec3789",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 33000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bdcffbaf-0dfe-41fa-8ea6-7489c347ee4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "전처리 함수 구현\n",
    "\"\"\"\n",
    "\n",
    "def unicode_to_ascii(s):\n",
    "    # 프랑스어 악센트(accent) 삭제\n",
    "    # 예시 : 'déjà diné' -> deja dine\n",
    "    return ''.join(c for c in unicodedata.normalize('NFD', s) if unicodedata.category(c) != 'Mn')\n",
    "\n",
    "def preprocess_sentence(sent):\n",
    "    # 악센트 삭제 함수 호출\n",
    "    sent = unicode_to_ascii(sent.lower())\n",
    "\n",
    "    # 단어와 구두점 사이에 공백을 만듭니다.\n",
    "    # Ex) \"he is a boy.\" => \"he is a boy .\"\n",
    "    sent = re.sub(r\"([?.!,¿])\", r\" \\1\", sent)\n",
    "\n",
    "    # (a-z, A-Z, \".\", \"?\", \"!\", \",\") 이들을 제외하고는 전부 공백으로 변환합니다.\n",
    "    sent = re.sub(r\"[^a-zA-Z!.?]+\", r\" \", sent)\n",
    "\n",
    "    # 다수 개의 공백을 하나의 공백으로 치환\n",
    "    sent = re.sub(r\"\\s+\", \" \", sent)\n",
    "    return sent\n",
    "\n",
    "def load_preprocessed_data():\n",
    "    encoder_input, decoder_input, decoder_target = [], [], []\n",
    "\n",
    "    with open(\"fra.txt\", \"r\", encoding='utf8') as lines:\n",
    "        for i, line in enumerate(lines):\n",
    "            # source 데이터와 target 데이터 분리\n",
    "            src_line, tar_line, _ = line.strip().split('\\t')\n",
    "\n",
    "            # source 데이터 전처리\n",
    "            src_line = [w for w in preprocess_sentence(src_line).split()]\n",
    "\n",
    "            # target 데이터 전처리\n",
    "            tar_line = preprocess_sentence(tar_line)\n",
    "            tar_line_in = [w for w in (\"<sos> \" + tar_line).split()]\n",
    "            tar_line_out = [w for w in (tar_line + \" <eos>\").split()]\n",
    "\n",
    "            encoder_input.append(src_line)\n",
    "            decoder_input.append(tar_line_in)\n",
    "            decoder_target.append(tar_line_out)\n",
    "\n",
    "            if i == num_samples - 1:\n",
    "                break\n",
    "\n",
    "    return encoder_input, decoder_input, decoder_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "818383e4-3822-4eb8-883f-f2ac0f30c4f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전처리 전 영어 문장 : Have you had dinner?\n",
      "전처리 후 영어 문장 : have you had dinner ?\n",
      "전처리 전 프랑스어 문장 : Avez-vous déjà diné?\n",
      "전처리 후 프랑스어 문장 : avez vous deja dine ?\n"
     ]
    }
   ],
   "source": [
    "# 전처리 테스트\n",
    "en_sent = u\"Have you had dinner?\"\n",
    "fr_sent = u\"Avez-vous déjà diné?\"\n",
    "\n",
    "print('전처리 전 영어 문장 :', en_sent)\n",
    "print('전처리 후 영어 문장 :', preprocess_sentence(en_sent))\n",
    "print('전처리 전 프랑스어 문장 :', fr_sent)\n",
    "print('전처리 후 프랑스어 문장 :', preprocess_sentence(fr_sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "210d9fed-9c91-422b-998b-481a0885c32e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인코더의 입력 : [['go', '.'], ['go', '.'], ['go', '.'], ['go', '.'], ['hi', '.']]\n",
      "디코더의 입력 : [['<sos>', 'va', '!'], ['<sos>', 'marche', '.'], ['<sos>', 'en', 'route', '!'], ['<sos>', 'bouge', '!'], ['<sos>', 'salut', '!']]\n",
      "디코더의 레이블 : [['va', '!', '<eos>'], ['marche', '.', '<eos>'], ['en', 'route', '!', '<eos>'], ['bouge', '!', '<eos>'], ['salut', '!', '<eos>']]\n"
     ]
    }
   ],
   "source": [
    "sents_en_in, sents_fra_in, sents_fra_out = load_preprocessed_data()\n",
    "print('인코더의 입력 :',sents_en_in[:5])\n",
    "print('디코더의 입력 :',sents_fra_in[:5])\n",
    "print('디코더의 레이블 :',sents_fra_out[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9df25e16-9093-4506-9ced-155daccf9f38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "영어 단어 집합의 크기 : 4486, 프랑스어 단어 집합의 크기 : 7879\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "단어로부터 정수를 얻는 딕셔너리. 즉, 단어 집합(Vocabulary) 생성\n",
    "\"\"\"\n",
    "def build_vocab(sents):\n",
    "    word_list = []\n",
    "\n",
    "    for sent in sents:\n",
    "        for word in sent:\n",
    "            word_list.append(word)\n",
    "\n",
    "    # 각 단어별 등장 빈도를 계산하여 등장 빈도가 높은 순서로 정렬\n",
    "    word_counts = Counter(word_list)\n",
    "    vocab = sorted(word_counts, key=word_counts.get, reverse=True)\n",
    "\n",
    "    word_to_index = {}\n",
    "    word_to_index['<PAD>'] = 0\n",
    "    word_to_index['<UNK>'] = 1\n",
    "\n",
    "    # 등장 빈도가 높은 단어일수록 낮은 정수를 부여\n",
    "    for index, word in enumerate(vocab) :\n",
    "        word_to_index[word] = index + 2\n",
    "\n",
    "    return word_to_index\n",
    "\n",
    "src_vocab = build_vocab(sents_en_in)\n",
    "tar_vocab = build_vocab(sents_fra_in + sents_fra_out)\n",
    "\n",
    "src_vocab_size = len(src_vocab)\n",
    "tar_vocab_size = len(tar_vocab)\n",
    "print(\"영어 단어 집합의 크기 : {:d}, 프랑스어 단어 집합의 크기 : {:d}\".format(src_vocab_size, tar_vocab_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "655c715d-d7c1-4e1c-9eb2-06eaddc5cbd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 33000/33000 [00:00<00:00, 1254925.72it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 33000/33000 [00:00<00:00, 1095751.42it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 33000/33000 [00:00<00:00, 314371.32it/s]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "정수로부터 단어를 얻는 딕셔너리를 각각 만들어줌. 이들은 훈련을 마치고 예측값과 실제값을 비교하는 단계에서 사용\n",
    "\"\"\"\n",
    "index_to_src = {v: k for k, v in src_vocab.items()}\n",
    "index_to_tar = {v: k for k, v in tar_vocab.items()}\n",
    "\n",
    "def texts_to_sequences(sents, word_to_index):\n",
    "    encoded_X_data = []\n",
    "    for sent in tqdm(sents):\n",
    "        index_sequences = []\n",
    "        for word in sent:\n",
    "            try:\n",
    "                index_sequences.append(word_to_index[word])\n",
    "            except KeyError:\n",
    "                index_sequences.append(word_to_index['<UNK>'])\n",
    "        encoded_X_data.append(index_sequences)\n",
    "    return encoded_X_data\n",
    "\n",
    "encoder_input = texts_to_sequences(sents_en_in, src_vocab)\n",
    "decoder_input = texts_to_sequences(sents_fra_in, tar_vocab)\n",
    "decoder_target = texts_to_sequences(sents_fra_out, tar_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "319bdd0f-1d29-4f35-9020-c895baae9ea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index: 0, 정수 인코딩 전: ['go', '.'], 정수 인코딩 후: [27, 2]\n",
      "Index: 1, 정수 인코딩 전: ['go', '.'], 정수 인코딩 후: [27, 2]\n",
      "Index: 2, 정수 인코딩 전: ['go', '.'], 정수 인코딩 후: [27, 2]\n",
      "Index: 3, 정수 인코딩 전: ['go', '.'], 정수 인코딩 후: [27, 2]\n",
      "Index: 4, 정수 인코딩 전: ['hi', '.'], 정수 인코딩 후: [736, 2]\n"
     ]
    }
   ],
   "source": [
    "# 상위 5개의 샘플에 대해서 정수 인코딩 전, 후 문장 출력\n",
    "# 인코더 입력이므로 <sos>나 <eos>가 없음\n",
    "for i, (item1, item2) in zip(range(5), zip(sents_en_in, encoder_input)):\n",
    "    print(f\"Index: {i}, 정수 인코딩 전: {item1}, 정수 인코딩 후: {item2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3ed69f04-417b-4740-b94e-7b884d5adadf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인코더의 입력의 크기(shape) : (33000, 7)\n",
      "디코더의 입력의 크기(shape) : (33000, 16)\n",
      "디코더의 레이블의 크기(shape) : (33000, 16)\n"
     ]
    }
   ],
   "source": [
    "def pad_sequences(sentences, max_len=None):\n",
    "    # 최대 길이 값이 주어지지 않을 경우 데이터 내 최대 길이로 패딩\n",
    "    if max_len is None:\n",
    "        max_len = max([len(sentence) for sentence in sentences])\n",
    "\n",
    "    features = np.zeros((len(sentences), max_len), dtype=int)\n",
    "    for index, sentence in enumerate(sentences):\n",
    "        if len(sentence) != 0:\n",
    "            features[index, :len(sentence)] = np.array(sentence)[:max_len]\n",
    "    return features\n",
    "\n",
    "encoder_input = pad_sequences(encoder_input)\n",
    "decoder_input = pad_sequences(decoder_input)\n",
    "decoder_target = pad_sequences(decoder_target)\n",
    "\n",
    "# 데이터 shape 확인\n",
    "print('인코더의 입력의 크기(shape) :', encoder_input.shape)\n",
    "print('디코더의 입력의 크기(shape) :', decoder_input.shape)\n",
    "print('디코더의 레이블의 크기(shape) :', decoder_target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1ab4942c-f8a5-4773-8d28-ea88b73c999b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33000, 7)\n",
      "랜덤 시퀀스 : [10977   714 29193 ... 23625 22401 19517]\n"
     ]
    }
   ],
   "source": [
    "# 테스트 데이터를 분리하기 전 데이터를 섞어줍니다. 이를 위해서 순서가 섞인 정수 시퀀스 리스트를 만듭니다.\n",
    "print(encoder_input.shape)\n",
    "indices = np.arange(encoder_input.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "print('랜덤 시퀀스 :', indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "840b0ca9-0b17-4d70-bfe6-e4f18ef68a72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'had', 'to', 'swim', '.', '<PAD>', '<PAD>']\n",
      "['<sos>', 'j', 'ai', 'du', 'nager', '.', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      "['j', 'ai', 'du', 'nager', '.', '<eos>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n"
     ]
    }
   ],
   "source": [
    "# 랜덤 시퀀스를 데이터셋의 순서로 지정\n",
    "print([index_to_src[word] for word in encoder_input[30997]])\n",
    "print([index_to_tar[word] for word in decoder_input[30997]])\n",
    "print([index_to_tar[word] for word in decoder_target[30997]])\n",
    "\n",
    "encoder_input = encoder_input[indices]\n",
    "decoder_input = decoder_input[indices]\n",
    "decoder_target = decoder_target[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d3c4bd1a-50a7-439d-8a17-2d9a2dda28bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['get', 'in', 'the', 'boat', '.', '<PAD>', '<PAD>']\n",
      "['<sos>', 'grimpe', 'dans', 'le', 'bateau', '!', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      "['grimpe', 'dans', 'le', 'bateau', '!', '<eos>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n"
     ]
    }
   ],
   "source": [
    "print([index_to_src[word] for word in encoder_input[30997]])\n",
    "print([index_to_tar[word] for word in decoder_input[30997]])\n",
    "print([index_to_tar[word] for word in decoder_target[30997]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "88b4b6e6-8550-40c2-b881-5ee4719ae5de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "검증 데이터의 개수 : 3300\n"
     ]
    }
   ],
   "source": [
    "# 10% 에 해당하는 데이터를 테스트 데이터로 사용\n",
    "n_of_val = int(33000*0.1)\n",
    "print('검증 데이터의 개수 :',n_of_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "cc7fba3b-7eb1-42ef-9fc0-ce693c5449b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train, test 분리\n",
    "encoder_input_train = encoder_input[:-n_of_val]\n",
    "decoder_input_train = decoder_input[:-n_of_val]\n",
    "decoder_target_train = decoder_target[:-n_of_val]\n",
    "\n",
    "encoder_input_test = encoder_input[-n_of_val:]\n",
    "decoder_input_test = decoder_input[-n_of_val:]\n",
    "decoder_target_test = decoder_target[-n_of_val:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d4bc8638-2c01-4acc-900c-32292c3beefd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 source 데이터의 크기 : (29700, 7)\n",
      "훈련 target 데이터의 크기 : (29700, 16)\n",
      "훈련 target 레이블의 크기 : (29700, 16)\n",
      "테스트 source 데이터의 크기 : (3300, 7)\n",
      "테스트 target 데이터의 크기 : (3300, 16)\n",
      "테스트 target 레이블의 크기 : (3300, 16)\n"
     ]
    }
   ],
   "source": [
    "print('훈련 source 데이터의 크기 :', encoder_input_train.shape)\n",
    "print('훈련 target 데이터의 크기 :', decoder_input_train.shape)\n",
    "print('훈련 target 레이블의 크기 :', decoder_target_train.shape)\n",
    "print('테스트 source 데이터의 크기 :', encoder_input_test.shape)\n",
    "print('테스트 target 데이터의 크기 :', decoder_input_test.shape)\n",
    "print('테스트 target 레이블의 크기 :', decoder_target_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "745c4b54-0e0a-4169-ab8c-6421ae2a3370",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "embedding_dim = 256\n",
    "hidden_units = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "5303b4d3-3f84-4364-94e3-9a5b57fea773",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4486\n",
      "7879\n"
     ]
    }
   ],
   "source": [
    "print(src_vocab_size)\n",
    "print(tar_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "23864353-15f0-4f06-a1d3-7cc00be5070e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, src_vocab_size, embedding_dim, hidden_units):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.embedding = nn.Embedding(src_vocab_size, embedding_dim, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_units, batch_first=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x.shape == (batch_size, seq_len, embedding_dim)\n",
    "        x = self.embedding(x)\n",
    "        # hidden.shape == (1, batch_size, hidden_units), cell.shape == (1, batch_size, hidden_units)\n",
    "        outputs, (hidden, cell) = self.lstm(x)\n",
    "        return outputs, hidden, cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7f1dc7e5-0d04-46b3-ae89-0b6b8d73d7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, tar_vocab_size, embedding_dim, hidden_units):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.embedding = nn.Embedding(tar_vocab_size, embedding_dim, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(embedding_dim + hidden_units, hidden_units, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_units, tar_vocab_size)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x, encoder_outputs, hidden, cell):\n",
    "        x = self.embedding(x)\n",
    "\n",
    "        # Dot product attention\n",
    "        # attention_scores.shape: (batch_size, source_seq_len, 1)\n",
    "        attention_scores = torch.bmm(encoder_outputs, hidden.transpose(0, 1).transpose(1, 2))\n",
    "\n",
    "        # attention_weights.shape: (batch_size, source_seq_len, 1)\n",
    "        attention_weights = self.softmax(attention_scores)\n",
    "\n",
    "        # context_vector.shape: (batch_size, 1, hidden_units)\n",
    "        context_vector = torch.bmm(attention_weights.transpose(1, 2), encoder_outputs)\n",
    "\n",
    "        # Repeat context_vector to match seq_len\n",
    "        # context_vector_repeated.shape: (batch_size, target_seq_len, hidden_units)\n",
    "        seq_len = x.shape[1]\n",
    "        context_vector_repeated = context_vector.repeat(1, seq_len, 1)\n",
    "\n",
    "        # Concatenate context vector and embedded input\n",
    "        # x.shape: (batch_size, target_seq_len, embedding_dim + hidden_units)\n",
    "        x = torch.cat((x, context_vector_repeated), dim=2)\n",
    "\n",
    "        # output.shape: (batch_size, target_seq_len, hidden_units)\n",
    "        # hidden.shape: (1, batch_size, hidden_units)\n",
    "        # cell.shape: (1, batch_size, hidden_units)\n",
    "        output, (hidden, cell) = self.lstm(x, (hidden, cell))\n",
    "\n",
    "        # output.shape: (batch_size, target_seq_len, tar_vocab_size)\n",
    "        output = self.fc(output)\n",
    "\n",
    "        return output, hidden, cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ace2ff17-0ff8-472c-a95e-8d38d883e76f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, src, trg):\n",
    "        encoder_outputs, hidden, cell = self.encoder(src)\n",
    "        output, _, _ = self.decoder(trg, encoder_outputs, hidden, cell)\n",
    "        return output\n",
    "\n",
    "encoder = Encoder(src_vocab_size, embedding_dim, hidden_units)\n",
    "decoder = Decoder(tar_vocab_size, embedding_dim, hidden_units)\n",
    "model = Seq2Seq(encoder, decoder)\n",
    "\n",
    "loss_function = nn.CrossEntropyLoss(ignore_index=0)\n",
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b1681b0a-1f57-40aa-ace1-e8afab7aa5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(model, dataloader, loss_function, device):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    total_correct = 0\n",
    "    total_count = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for encoder_inputs, decoder_inputs, decoder_targets in dataloader:\n",
    "            encoder_inputs = encoder_inputs.to(device)\n",
    "            decoder_inputs = decoder_inputs.to(device)\n",
    "            decoder_targets = decoder_targets.to(device)\n",
    "\n",
    "            # 순방향 전파\n",
    "            # outputs.shape == (batch_size, seq_len, tar_vocab_size)\n",
    "            outputs = model(encoder_inputs, decoder_inputs)\n",
    "\n",
    "            # 손실 계산\n",
    "            # outputs.view(-1, outputs.size(-1))의 shape는 (batch_size * seq_len, tar_vocab_size)\n",
    "            # decoder_targets.view(-1)의 shape는 (batch_size * seq_len)\n",
    "            loss = loss_function(outputs.view(-1, outputs.size(-1)), decoder_targets.view(-1))\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # 정확도 계산 (패딩 토큰 제외)\n",
    "            mask = decoder_targets != 0\n",
    "            total_correct += ((outputs.argmax(dim=-1) == decoder_targets) * mask).sum().item()\n",
    "            total_count += mask.sum().item()\n",
    "\n",
    "    return total_loss / len(dataloader), total_correct / total_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dd6911a3-aa70-4636-8ef3-d37ae17fe7f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (encoder): Encoder(\n",
       "    (embedding): Embedding(4486, 256, padding_idx=0)\n",
       "    (lstm): LSTM(256, 256, batch_first=True)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (embedding): Embedding(7879, 256, padding_idx=0)\n",
       "    (lstm): LSTM(512, 256, batch_first=True)\n",
       "    (fc): Linear(in_features=256, out_features=7879, bias=True)\n",
       "    (softmax): Softmax(dim=1)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_input_train_tensor = torch.tensor(encoder_input_train, dtype=torch.long)\n",
    "decoder_input_train_tensor = torch.tensor(decoder_input_train, dtype=torch.long)\n",
    "decoder_target_train_tensor = torch.tensor(decoder_target_train, dtype=torch.long)\n",
    "\n",
    "encoder_input_test_tensor = torch.tensor(encoder_input_test, dtype=torch.long)\n",
    "decoder_input_test_tensor = torch.tensor(decoder_input_test, dtype=torch.long)\n",
    "decoder_target_test_tensor = torch.tensor(decoder_target_test, dtype=torch.long)\n",
    "\n",
    "# 데이터셋 및 데이터로더 생성\n",
    "batch_size = 128\n",
    "\n",
    "train_dataset = TensorDataset(encoder_input_train_tensor, decoder_input_train_tensor, decoder_target_train_tensor)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "valid_dataset = TensorDataset(encoder_input_test_tensor, decoder_input_test_tensor, decoder_target_test_tensor)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# 학습 설정\n",
    "num_epochs = 30\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f63838ee-355a-4896-947b-cd324c10ab53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/30 | Train Loss: 2.8923 | Train Acc: 0.5393 | Valid Loss: 3.0150 | Valid Acc: 0.5346\n",
      "Validation loss improved from inf to 3.0150. 체크포인트를 저장합니다.\n",
      "Epoch: 2/30 | Train Loss: 2.2219 | Train Acc: 0.6129 | Valid Loss: 2.4610 | Valid Acc: 0.5968\n",
      "Validation loss improved from 3.0150 to 2.4610. 체크포인트를 저장합니다.\n",
      "Epoch: 3/30 | Train Loss: 1.7897 | Train Acc: 0.6567 | Valid Loss: 2.1557 | Valid Acc: 0.6265\n",
      "Validation loss improved from 2.4610 to 2.1557. 체크포인트를 저장합니다.\n",
      "Epoch: 4/30 | Train Loss: 1.4662 | Train Acc: 0.6971 | Valid Loss: 1.9486 | Valid Acc: 0.6534\n",
      "Validation loss improved from 2.1557 to 1.9486. 체크포인트를 저장합니다.\n",
      "Epoch: 5/30 | Train Loss: 1.2041 | Train Acc: 0.7394 | Valid Loss: 1.7958 | Valid Acc: 0.6733\n",
      "Validation loss improved from 1.9486 to 1.7958. 체크포인트를 저장합니다.\n",
      "Epoch: 6/30 | Train Loss: 0.9835 | Train Acc: 0.7795 | Valid Loss: 1.6802 | Valid Acc: 0.6909\n",
      "Validation loss improved from 1.7958 to 1.6802. 체크포인트를 저장합니다.\n",
      "Epoch: 7/30 | Train Loss: 0.8035 | Train Acc: 0.8147 | Valid Loss: 1.5963 | Valid Acc: 0.7022\n",
      "Validation loss improved from 1.6802 to 1.5963. 체크포인트를 저장합니다.\n",
      "Epoch: 8/30 | Train Loss: 0.6456 | Train Acc: 0.8466 | Valid Loss: 1.5329 | Valid Acc: 0.7136\n",
      "Validation loss improved from 1.5963 to 1.5329. 체크포인트를 저장합니다.\n",
      "Epoch: 9/30 | Train Loss: 0.5310 | Train Acc: 0.8700 | Valid Loss: 1.4949 | Valid Acc: 0.7192\n",
      "Validation loss improved from 1.5329 to 1.4949. 체크포인트를 저장합니다.\n",
      "Epoch: 10/30 | Train Loss: 0.4468 | Train Acc: 0.8872 | Valid Loss: 1.4708 | Valid Acc: 0.7255\n",
      "Validation loss improved from 1.4949 to 1.4708. 체크포인트를 저장합니다.\n",
      "Epoch: 11/30 | Train Loss: 0.3792 | Train Acc: 0.9007 | Valid Loss: 1.4544 | Valid Acc: 0.7263\n",
      "Validation loss improved from 1.4708 to 1.4544. 체크포인트를 저장합니다.\n",
      "Epoch: 12/30 | Train Loss: 0.3275 | Train Acc: 0.9095 | Valid Loss: 1.4462 | Valid Acc: 0.7258\n",
      "Validation loss improved from 1.4544 to 1.4462. 체크포인트를 저장합니다.\n",
      "Epoch: 13/30 | Train Loss: 0.2917 | Train Acc: 0.9152 | Valid Loss: 1.4508 | Valid Acc: 0.7284\n",
      "Epoch: 14/30 | Train Loss: 0.2600 | Train Acc: 0.9202 | Valid Loss: 1.4587 | Valid Acc: 0.7306\n",
      "Epoch: 15/30 | Train Loss: 0.2403 | Train Acc: 0.9232 | Valid Loss: 1.4614 | Valid Acc: 0.7309\n",
      "Epoch: 16/30 | Train Loss: 0.2232 | Train Acc: 0.9260 | Valid Loss: 1.4711 | Valid Acc: 0.7300\n",
      "Epoch: 17/30 | Train Loss: 0.2093 | Train Acc: 0.9270 | Valid Loss: 1.4892 | Valid Acc: 0.7293\n",
      "Epoch: 18/30 | Train Loss: 0.2011 | Train Acc: 0.9284 | Valid Loss: 1.5013 | Valid Acc: 0.7310\n",
      "Epoch: 19/30 | Train Loss: 0.1941 | Train Acc: 0.9290 | Valid Loss: 1.5033 | Valid Acc: 0.7271\n",
      "Epoch: 20/30 | Train Loss: 0.1853 | Train Acc: 0.9301 | Valid Loss: 1.5217 | Valid Acc: 0.7278\n",
      "Epoch: 21/30 | Train Loss: 0.1808 | Train Acc: 0.9300 | Valid Loss: 1.5320 | Valid Acc: 0.7290\n",
      "Epoch: 22/30 | Train Loss: 0.1738 | Train Acc: 0.9313 | Valid Loss: 1.5326 | Valid Acc: 0.7300\n",
      "Epoch: 23/30 | Train Loss: 0.1718 | Train Acc: 0.9306 | Valid Loss: 1.5459 | Valid Acc: 0.7292\n",
      "Epoch: 24/30 | Train Loss: 0.1662 | Train Acc: 0.9318 | Valid Loss: 1.5599 | Valid Acc: 0.7299\n",
      "Epoch: 25/30 | Train Loss: 0.1618 | Train Acc: 0.9319 | Valid Loss: 1.5612 | Valid Acc: 0.7305\n",
      "Epoch: 26/30 | Train Loss: 0.1597 | Train Acc: 0.9322 | Valid Loss: 1.5740 | Valid Acc: 0.7301\n",
      "Epoch: 27/30 | Train Loss: 0.1592 | Train Acc: 0.9324 | Valid Loss: 1.5767 | Valid Acc: 0.7306\n",
      "Epoch: 28/30 | Train Loss: 0.1583 | Train Acc: 0.9321 | Valid Loss: 1.5857 | Valid Acc: 0.7334\n",
      "Epoch: 29/30 | Train Loss: 0.1591 | Train Acc: 0.9316 | Valid Loss: 1.6170 | Valid Acc: 0.7268\n",
      "Epoch: 30/30 | Train Loss: 0.1555 | Train Acc: 0.9322 | Valid Loss: 1.6064 | Valid Acc: 0.7284\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # 훈련 모드\n",
    "    model.train()\n",
    "\n",
    "    for encoder_inputs, decoder_inputs, decoder_targets in train_dataloader:\n",
    "        encoder_inputs = encoder_inputs.to(device)\n",
    "        decoder_inputs = decoder_inputs.to(device)\n",
    "        decoder_targets = decoder_targets.to(device)\n",
    "\n",
    "        # 기울기 초기화\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 순방향 전파\n",
    "        # outputs.shape == (batch_size, seq_len, tar_vocab_size)\n",
    "        outputs = model(encoder_inputs, decoder_inputs)\n",
    "\n",
    "        # 손실 계산 및 역방향 전파\n",
    "        # outputs.view(-1, outputs.size(-1))의 shape는 (batch_size * seq_len, tar_vocab_size)\n",
    "        # decoder_targets.view(-1)의 shape는 (batch_size * seq_len)\n",
    "        loss = loss_function(outputs.view(-1, outputs.size(-1)), decoder_targets.view(-1))\n",
    "        loss.backward()\n",
    "\n",
    "        # 가중치 업데이트\n",
    "        optimizer.step()\n",
    "\n",
    "    train_loss, train_acc = evaluation(model, train_dataloader, loss_function, device)\n",
    "    valid_loss, valid_acc = evaluation(model, valid_dataloader, loss_function, device)\n",
    "\n",
    "    print(f'Epoch: {epoch+1}/{num_epochs} | Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f} | Valid Loss: {valid_loss:.4f} | Valid Acc: {valid_acc:.4f}')\n",
    "\n",
    "    # 검증 손실이 최소일 때 체크포인트 저장\n",
    "    if valid_loss < best_val_loss:\n",
    "        print(f'Validation loss improved from {best_val_loss:.4f} to {valid_loss:.4f}. 체크포인트를 저장합니다.')\n",
    "        best_val_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'best_model_checkpoint.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5902aebf-ad17-42f9-9eab-77cc8d31e5ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model validation loss: 1.4462\n",
      "Best model validation accuracy: 0.7258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amps\\AppData\\Local\\Temp\\ipykernel_27944\\2929441124.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('best_model_checkpoint.pth'))\n"
     ]
    }
   ],
   "source": [
    "# 모델 로드\n",
    "model.load_state_dict(torch.load('best_model_checkpoint.pth'))\n",
    "\n",
    "# 모델을 device에 올립니다.\n",
    "model.to(device)\n",
    "\n",
    "# 검증 데이터에 대한 정확도와 손실 계산\n",
    "val_loss, val_accuracy = evaluation(model, valid_dataloader, loss_function, device)\n",
    "\n",
    "print(f'Best model validation loss: {val_loss:.4f}')\n",
    "print(f'Best model validation accuracy: {val_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "55bf790e-197b-44c1-91e0-9ca602c82909",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "print(tar_vocab['<sos>'])\n",
    "print(tar_vocab['<eos>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6c6b8833-0697-431f-b8d7-a810f2488b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_to_src = {v: k for k, v in src_vocab.items()}\n",
    "index_to_tar = {v: k for k, v in tar_vocab.items()}\n",
    "\n",
    "# 원문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
    "def seq_to_src(input_seq):\n",
    "    sentence = ''\n",
    "    for encoded_word in input_seq:\n",
    "        if(encoded_word != 0):\n",
    "            sentence = sentence + index_to_src[encoded_word] + ' '\n",
    "    return sentence\n",
    "\n",
    "# 번역문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
    "def seq_to_tar(input_seq):\n",
    "    sentence = ''\n",
    "    for encoded_word in input_seq:\n",
    "        if(encoded_word != 0 and encoded_word != tar_vocab['<sos>'] and encoded_word != tar_vocab['<eos>']):\n",
    "            sentence = sentence + index_to_tar[encoded_word] + ' '\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7da418f8-b9ed-4c00-8ef3-d3290ec12594",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 29  10  74 174   2   0   0]\n",
      "[  3 897  33 145 312   2   0   0   0   0   0   0   0   0   0   0]\n",
      "[897  33 145 312   2   4   0   0   0   0   0   0   0   0   0   0]\n"
     ]
    }
   ],
   "source": [
    "print(encoder_input_test[25])\n",
    "print(decoder_input_test[25])\n",
    "print(decoder_target_test[25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3023118e-2349-4500-87f1-9991ea92b573",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq, model, src_vocab_size, tar_vocab_size, max_output_len, int_to_src_token, int_to_tar_token):\n",
    "    encoder_inputs = torch.tensor(input_seq, dtype=torch.long).unsqueeze(0).to(device)\n",
    "\n",
    "    # 인코더의 초기 상태 설정\n",
    "    encoder_outputs, hidden, cell = model.encoder(encoder_inputs)\n",
    "\n",
    "    # 시작 토큰 <sos>을 디코더의 첫 입력으로 설정\n",
    "    # unsqueeze(0)는 배치 차원을 추가하기 위함.\n",
    "    decoder_input = torch.tensor([3], dtype=torch.long).unsqueeze(0).to(device)\n",
    "\n",
    "    decoded_tokens = []\n",
    "\n",
    "    # for문을 도는 것 == 디코더의 각 시점\n",
    "    for _ in range(max_output_len):\n",
    "        output, hidden, cell = model.decoder(decoder_input, encoder_outputs, hidden, cell)\n",
    "\n",
    "        # 소프트맥스 회귀를 수행. 예측 단어의 인덱스\n",
    "        output_token = output.argmax(dim=-1).item()\n",
    "\n",
    "        # 종료 토큰 <eos>\n",
    "        if output_token == 4:\n",
    "            break\n",
    "\n",
    "        # 각 시점의 단어(정수)는 decoded_tokens에 누적하였다가 최종 번역 시퀀스로 리턴합니다.\n",
    "        decoded_tokens.append(output_token)\n",
    "\n",
    "        # 현재 시점의 예측. 다음 시점의 입력으로 사용된다.\n",
    "        decoder_input = torch.tensor([output_token], dtype=torch.long).unsqueeze(0).to(device)\n",
    "\n",
    "    return ' '.join(int_to_tar_token[token] for token in decoded_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2a24c1c9-8b78-4125-846a-9c0a5f378062",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력문장 : watch the door . \n",
      "정답문장 : surveillez la porte ! \n",
      "번역문장 : surveillez la porte !\n",
      "--------------------------------------------------\n",
      "입력문장 : i needed to vent . \n",
      "정답문장 : j avais besoin de vider mon sac . \n",
      "번역문장 : il fallait que j avais besoin de mon cote .\n",
      "--------------------------------------------------\n",
      "입력문장 : tom was terrific . \n",
      "정답문장 : tom etait formidable . \n",
      "번역문장 : tom etait formidable .\n",
      "--------------------------------------------------\n",
      "입력문장 : boy was i wrong . \n",
      "정답문장 : combien j avais tort ! \n",
      "번역문장 : j avais tort .\n",
      "--------------------------------------------------\n",
      "입력문장 : i m on my way . \n",
      "정답문장 : je suis en chemin . \n",
      "번역문장 : je suis en chemin .\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for seq_index in [3, 50, 100, 300, 1001]:\n",
    "    input_seq = encoder_input_train[seq_index]\n",
    "    translated_text = decode_sequence(input_seq, model, src_vocab_size, tar_vocab_size, 20, index_to_src, index_to_tar)\n",
    "\n",
    "    print(\"입력문장 :\",seq_to_src(encoder_input_train[seq_index]))\n",
    "    print(\"정답문장 :\",seq_to_tar(decoder_input_train[seq_index]))\n",
    "    print(\"번역문장 :\",translated_text)\n",
    "    print(\"-\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9d877922-c676-43fc-a68c-8de9f41fe053",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력문장 : tom exercises . \n",
      "정답문장 : tom s exerce . \n",
      "번역문장 : tom a ecoute .\n",
      "--------------------------------------------------\n",
      "입력문장 : we ll survive . \n",
      "정답문장 : nous survivrons . \n",
      "번역문장 : nous reussirons .\n",
      "--------------------------------------------------\n",
      "입력문장 : i had to be sure . \n",
      "정답문장 : je devais etre sur . \n",
      "번역문장 : je devais etre sure .\n",
      "--------------------------------------------------\n",
      "입력문장 : i messed up . \n",
      "정답문장 : j ai mis la pagaille . \n",
      "번역문장 : j ai merde .\n",
      "--------------------------------------------------\n",
      "입력문장 : who are you ? \n",
      "정답문장 : qui es tu ? \n",
      "번역문장 : qui etes vous ?\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for seq_index in [3, 50, 100, 300, 1001]:\n",
    "    input_seq = encoder_input_test[seq_index]\n",
    "    translated_text = decode_sequence(input_seq, model, src_vocab_size, tar_vocab_size, 20, index_to_src, index_to_tar)\n",
    "\n",
    "    print(\"입력문장 :\",seq_to_src(encoder_input_test[seq_index]))\n",
    "    print(\"정답문장 :\",seq_to_tar(decoder_input_test[seq_index]))\n",
    "    print(\"번역문장 :\",translated_text)\n",
    "    print(\"-\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba694d5b-2ff5-46e7-bb9a-e4cf49428387",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab1f169-14f2-4c06-84ba-1ff0b4e55b05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b95773d-5db4-40ff-8f22-b1bbcaf50cbb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_study",
   "language": "python",
   "name": "dl_study"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
