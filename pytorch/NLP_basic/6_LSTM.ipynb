{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8de7536a-4d22-4848-bea1-d5690c81c560",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7da031da-46a6-458f-aeed-83af84d0f4e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문자 집합의 크기 : 5\n"
     ]
    }
   ],
   "source": [
    "input_str = 'apple'\n",
    "label_str = 'pple!'\n",
    "char_vocab = sorted(list(set(input_str+label_str)))\n",
    "vocab_size = len(char_vocab)\n",
    "print ('문자 집합의 크기 : {}'.format(vocab_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "95f36cac-eeb2-4393-9ed0-fa4938b07f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = vocab_size # 입력의 크기는 문자 집합의 크기\n",
    "hidden_size = 5\n",
    "output_size = 5\n",
    "learning_rate = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "507fc95e-28a4-4228-a687-b22963721ead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'!': 0, 'a': 1, 'e': 2, 'l': 3, 'p': 4}\n"
     ]
    }
   ],
   "source": [
    "char_to_index = dict((c, i) for i, c in enumerate(char_vocab)) # 문자에 고유한 정수 인덱스 부여\n",
    "print(char_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8eae9f64-11d9-4cfe-a955-add4d1817cd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: '!', 1: 'a', 2: 'e', 3: 'l', 4: 'p'}\n"
     ]
    }
   ],
   "source": [
    "index_to_char={}\n",
    "for key, value in char_to_index.items():\n",
    "    index_to_char[value] = key\n",
    "print(index_to_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "65c12c35-0a90-4076-9552-25c1a88f4e93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 4, 4, 3, 2]\n",
      "[4, 4, 3, 2, 0]\n"
     ]
    }
   ],
   "source": [
    "x_data = [char_to_index[c] for c in input_str]\n",
    "y_data = [char_to_index[c] for c in label_str]\n",
    "print(x_data)\n",
    "print(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9424b8dd-5708-4f84-9741-4133e63d2d35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 4, 4, 3, 2]]\n",
      "[[4, 4, 3, 2, 0]]\n"
     ]
    }
   ],
   "source": [
    "# 배치 차원 추가\n",
    "# 텐서 연산인 unsqueeze(0)를 통해 해결할 수도 있었음.\n",
    "x_data = [x_data]\n",
    "y_data = [y_data]\n",
    "print(x_data)\n",
    "print(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a9903882-86fd-43f4-b8de-bcb8f71916ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[0., 1., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 1.],\n",
      "       [0., 0., 0., 0., 1.],\n",
      "       [0., 0., 0., 1., 0.],\n",
      "       [0., 0., 1., 0., 0.]])]\n"
     ]
    }
   ],
   "source": [
    "x_one_hot = [np.eye(vocab_size)[x] for x in x_data]\n",
    "print(x_one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1954f357-4991-4bae-af4c-0d07d8af71d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amps\\AppData\\Local\\Temp\\ipykernel_8336\\2348034151.py:1: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\tensor_new.cpp:281.)\n",
      "  X = torch.FloatTensor(x_one_hot)\n"
     ]
    }
   ],
   "source": [
    "X = torch.FloatTensor(x_one_hot)\n",
    "Y = torch.LongTensor(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9c941bce-397e-4532-9591-468f5de47c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 데이터의 크기 : torch.Size([1, 5, 5])\n",
      "레이블의 크기 : torch.Size([1, 5])\n"
     ]
    }
   ],
   "source": [
    "print('훈련 데이터의 크기 : {}'.format(X.shape))\n",
    "print('레이블의 크기 : {}'.format(Y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ff777a50-931d-4f11-b9a3-3abb1fad4a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(Net, self).__init__()\n",
    "        self.rnn = torch.nn.RNN(input_size, hidden_size, batch_first=True) # RNN 셀 구현\n",
    "        self.fc = torch.nn.Linear(hidden_size, output_size, bias=True) # 출력층 구현\n",
    "\n",
    "    def forward(self, x): # 구현한 RNN 셀과 출력층을 연결\n",
    "        x, _status = self.rnn(x)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f66afd-542a-4e44-a092-9488cd4bace6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_size, output_size):\n",
    "        super(Net, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)  # vocab_size는 어휘 크기, embedding_dim은 임베딩 차원\n",
    "        self.rnn = nn.RNN(embedding_dim, hidden_size, batch_first=True)  # RNN 셀 구현\n",
    "        self.fc = nn.Linear(hidden_size, output_size)  # 출력층 구현\n",
    "\n",
    "    def forward(self, x):  # 구현한 RNN 셀과 출력층을 연결\n",
    "        # 입력 x는 (batch_size, seq_length) 형태입니다.\n",
    "        x = self.embedding(x)  # 임베딩을 적용하여 (batch_size, seq_length, embedding_dim) 형태로 변환\n",
    "        x, _ = self.rnn(x)  # RNN 셀에 통과\n",
    "        x = self.fc(x[:, -1, :])  # 마지막 시퀀스의 출력만 사용 (batch_size, hidden_size)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffaa2774-e903-4b50-b7c5-1b0d9d5c89ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim):\n",
    "        super(TextClassifier, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (batch_size, seq_length)\n",
    "        embedded = self.embedding(x)  # (batch_size, seq_length, embedding_dim)\n",
    "        lstm_out, (hidden, cell) = self.lstm(embedded)  # lstm_out: (batch_size, seq_length, hidden_dim), hidden: (1, batch_size, hidden_dim)\n",
    "        last_hidden = hidden.squeeze(0)  # (batch_size, hidden_dim)\n",
    "        logits = self.fc(last_hidden)  # (batch_size, output_dim)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37738e64-322b-4418-8768-c0f685e9337c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim):\n",
    "        super(TextClassifier, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = nn.GRU(embedding_dim, hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim) # output_dim = 분류하고자하는 카테고리의 개수\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (batch_size, seq_length) == (32, 500)\n",
    "        embedded = self.embedding(x)  # (batch_size, seq_length, embedding_dim) == (32, 500, 100) == (데이터의 개수, 문장길이, 단어 벡터의 차원)\n",
    "        gru_out, hidden = self.gru(embedded)  # gru_out: (batch_size, seq_length, hidden_dim), hidden: (1, batch_size, hidden_dim)\n",
    "        last_hidden = hidden.squeeze(0)  # (batch_size, hidden_dim)\n",
    "        logits = self.fc(last_hidden)  # (batch_size, output_dim)\n",
    "        return logits"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_study",
   "language": "python",
   "name": "dl_study"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
